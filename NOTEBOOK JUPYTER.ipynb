{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5636a9c4",
   "metadata": {},
   "source": [
    "# **I. LIBRAIRIES & DATA.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40fc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "# RECUP LA DATA\n",
    "# Retrieve the path to the current folders\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# Get the path to the csv file folder - in this case the 'data' file\n",
    "csv_path = os.path.join(current_path, 'data\\\\test')\n",
    "\n",
    "# A EXPLIQUER ICI\n",
    "for file in os.listdir(csv_path):\n",
    "    fd = pd.read_csv(os.path.join(csv_path, file))\n",
    "    globals()[file.rpartition(\".\")[0]] = fd\n",
    "\n",
    "# fillna\n",
    "Moon = Moon.copy()\n",
    "Moon.fillna(0, inplace=True)\n",
    "\n",
    "lat_moon_changes = lat_moon_changes.copy()\n",
    "lat_moon_changes.fillna(0, inplace=True)\n",
    "\n",
    "planet_node = planet_node.copy()\n",
    "planet_node.fillna(0, inplace=True)\n",
    "\n",
    "twoday = datetime.strftime(datetime.now(), \"%Y/%m/%d\")\n",
    "t = pd.to_datetime(twoday)\n",
    "t = pd.to_datetime(t)\n",
    "\n",
    "today = datetime.strftime(datetime.now(), \"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12efcb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___\n",
      "343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361\n",
      "342 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290\n",
      "341 272 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 291\n",
      "340 271 210 157 158 159 160 161 162 163 164 165 166 167 168 169 170 227 292\n",
      "339 270 209 156 111 112 113 114 115 116 117 118 119 120 121 122 171 228 293\n",
      "338 269 208 155 110 073 074 075 076 077 078 079 080 081 082 123 172 229 294\n",
      "337 268 207 154 109 072 043 044 045 046 047 048 049 050 083 124 173 230 295\n",
      "336 267 206 153 108 071 042 021 022 023 024 025 026 051 084 125 174 231 296\n",
      "335 266 205 152 107 070 041 020 007 008 009 010 027 052 085 126 175 232 297\n",
      "334 265 204 151 106 069 040 019 006 001 002 011 028 053 086 127 176 233 298\n",
      "333 264 203 150 105 068 039 018 005 004 003 012 029 054 087 128 177 234 299\n",
      "332 263 202 149 104 067 038 017 016 015 014 013 030 055 088 129 178 235 300\n",
      "331 262 201 148 103 066 037 036 035 034 033 032 031 056 089 130 179 236 301\n",
      "330 261 200 147 102 065 064 063 062 061 060 059 058 057 090 131 180 237 302\n",
      "329 260 199 146 101 100 099 098 097 096 095 094 093 092 091 132 181 238 303\n",
      "328 259 198 145 144 143 142 141 140 139 138 137 136 135 134 133 182 239 304\n",
      "327 258 197 196 195 194 193 192 191 190 189 188 187 186 185 184 183 240 305\n",
      "326 257 256 255 254 253 252 251 250 249 248 247 246 245 244 243 242 241 306\n",
      "325 324 323 322 321 320 319 318 317 316 315 314 313 312 311 310 309 308 307\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "NORTH, S, W, E = (0, -1), (0, 1), (-1, 0), (1, 0) # directions\n",
    "turn_right = {S: W, W: NORTH, NORTH: E, E: S} # old -> new direction\n",
    "\n",
    "def spiral(width, height):\n",
    "    if width < 1 or height < 1:\n",
    "        raise ValueError\n",
    "    x, y = width // 2, height // 2 # start near the center\n",
    "    dx, dy = NORTH # initial direction\n",
    "    matrix = [[None] * width for _ in range(height)]\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        matrix[y][x] = count # visit\n",
    "        # try to turn right\n",
    "        new_dx, new_dy = turn_right[dx,dy]\n",
    "        new_x, new_y = x + new_dx, y + new_dy\n",
    "        if (0 <= new_x < width and 0 <= new_y < height and\n",
    "            matrix[new_y][new_x] is None): # can turn right\n",
    "            x, y = new_x, new_y\n",
    "            dx, dy = new_dx, new_dy\n",
    "        else: # try to move straight\n",
    "            x, y = x + dx, y + dy\n",
    "            if not (0 <= x < width and 0 <= y < height):\n",
    "                return matrix # nowhere to go\n",
    "\n",
    "def print_matrix(matrix):\n",
    "    width = len(str(max(el for row in matrix for el in row if el is not None)))\n",
    "    fmt = \"{:0%dd}\" % width\n",
    "    for row in matrix:\n",
    "        print(\" \".join(\"_\"*width if el is None else fmt.format(el) for el in row))\n",
    "\n",
    "print_matrix(spiral(19,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fddef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___ ___\n",
      "343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361\n",
      "342 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290\n",
      "341 272 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 291\n",
      "340 271 210 157 158 159 160 161 162 163 164 165 166 167 168 169 170 227 292\n",
      "339 270 209 156 111 112 113 114 115 116 117 118 119 120 121 122 171 228 293\n",
      "338 269 208 155 110 073 074 075 076 077 078 079 080 081 082 123 172 229 294\n",
      "337 268 207 154 109 072 043 044 045 046 047 048 049 050 083 124 173 230 295\n",
      "336 267 206 153 108 071 042 021 022 023 024 025 026 051 084 125 174 231 296\n",
      "335 266 205 152 107 070 041 020 007 008 009 010 027 052 085 126 175 232 297\n",
      "334 265 204 151 106 069 040 019 006 001 002 011 028 053 086 127 176 233 298\n",
      "333 264 203 150 105 068 039 018 005 004 003 012 029 054 087 128 177 234 299\n",
      "332 263 202 149 104 067 038 017 016 015 014 013 030 055 088 129 178 235 300\n",
      "331 262 201 148 103 066 037 036 035 034 033 032 031 056 089 130 179 236 301\n",
      "330 261 200 147 102 065 064 063 062 061 060 059 058 057 090 131 180 237 302\n",
      "329 260 199 146 101 100 099 098 097 096 095 094 093 092 091 132 181 238 303\n",
      "328 259 198 145 144 143 142 141 140 139 138 137 136 135 134 133 182 239 304\n",
      "327 258 197 196 195 194 193 192 191 190 189 188 187 186 185 184 183 240 305\n",
      "326 257 256 255 254 253 252 251 250 249 248 247 246 245 244 243 242 241 306\n",
      "325 324 323 322 321 320 319 318 317 316 315 314 313 312 311 310 309 308 307\n"
     ]
    }
   ],
   "source": [
    "ssd = print_matrix(spiral(19,20))\n",
    "ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279df76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gannsquare = gannsquare.copy()\n",
    "gannsquare.drop(gannsquare.columns[len(gannsquare.columns)-1], axis=1, inplace=True)\n",
    "\n",
    "gannsquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9588e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND NEAREST FUNCTION\n",
    "\n",
    "def find_nearest(array,value): \n",
    "    idx = (np.abs(array-value)).argmin() \n",
    "    return array[idx]\n",
    "\n",
    "helio_cum = helio_cum.copy()\n",
    "ex = helio_cum.Ven.array\n",
    "\n",
    "find_nearest(ex, 50286.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc68f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"31/10/2008\", \"%d/%m/%Y\")\n",
    "\n",
    "input1 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\"],\n",
    "                       \"Degrees\": [365.2425, 88],\n",
    "                       \"Rev\": \"\",\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "\n",
    "input2 = pd.DataFrame({\"Earth\": [\"13\", \"13\", \"12\"],\n",
    "                       \"Mer\": [\"57\", \"56\", \"51\"]\n",
    "                       })\n",
    "\n",
    "input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ead046",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_date = datetime.datetime.strptime(\"31/10/2008\", \"%d/%m/%Y\")\n",
    "\n",
    "output2008 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\"],\n",
    "                       \"Degrees\": [365.2425, 88],\n",
    "                       \"Rev\": [\"13\", \"57\"],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "\n",
    "output2009 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\"],\n",
    "                       \"Degrees\": [365.2425, 88],\n",
    "                       \"Rev\": [\"13\", \"56\"],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "\n",
    "output2010 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\"],\n",
    "                       \"Degrees\": [365.2425, 88],\n",
    "                       \"Rev\": [\"12\", \"51\"],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "\n",
    "output2010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e1b765",
   "metadata": {},
   "source": [
    "# **II. MAIN TABLE.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b479e620",
   "metadata": {},
   "source": [
    "## **II.1 HELIO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f413c48",
   "metadata": {},
   "source": [
    "### **II.1.1 CUMULATIVE HELIO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = datetime.strftime(datetime.now(), \"%d/%m/%Y\")\n",
    "\n",
    "cumulative_1 = helio_cum.copy()\n",
    "cumulative_2 = helio_cum.copy()\n",
    "cumulative_3 = helio_cum.copy()\n",
    "cumulative_4 = helio_cum.copy()\n",
    "cumulative_5 = helio_cum.copy()\n",
    "cumulative_6 = helio_cum.copy()\n",
    "cumulative_7 = helio_cum.copy()\n",
    "cumulative_8 = helio_cum.copy()\n",
    "cumulative_9 = helio_cum.copy()\n",
    "cumulative_10 = helio_cum.copy()\n",
    "cumulative_11 = helio_cum.copy()\n",
    "cumulative_12 = helio_cum.copy()\n",
    "cumulative_13 = helio_cum.copy()\n",
    "\n",
    "helio = helio.copy()\n",
    "test = helio_cum.copy()\n",
    "\n",
    "result = helio[helio.Date == today]\n",
    "\n",
    "def cum_hel(df, date):\n",
    "    today = datetime.strftime(datetime.now(), \"%d/%m/%Y\")\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"Date\": [date],\n",
    "            \"Earth\": df[\"Earth\"][df.Date == today].values\n",
    "            - df[\"Earth\"][df.Date == date].values,\n",
    "            \"Mer\": df[\"Mer\"][df.Date == today].values\n",
    "            - df[\"Mer\"][df.Date == date].values,\n",
    "            \"Ven\": df[\"Ven\"][df.Date == today].values\n",
    "            - df[\"Ven\"][df.Date == date].values,\n",
    "            \"Mar\": df[\"Mar\"][df.Date == today].values\n",
    "            - df[\"Mar\"][df.Date == date].values,\n",
    "            \"Jup\": df[\"Jup\"][df.Date == today].values\n",
    "            - df[\"Jup\"][df.Date == date].values,\n",
    "            \"Sat\": df[\"Sat\"][df.Date == today].values\n",
    "            - df[\"Sat\"][df.Date == date].values,\n",
    "            \"Ura\": df[\"Ura\"][df.Date == today].values\n",
    "            - df[\"Ura\"][df.Date == date].values,\n",
    "            \"Nep\": df[\"Nep\"][df.Date == today].values\n",
    "            - df[\"Nep\"][df.Date == date].values,\n",
    "            \"Plu\": df[\"Plu\"][df.Date == today].values\n",
    "            - df[\"Plu\"][df.Date == date].values,\n",
    "        }\n",
    "    )\n",
    "\n",
    "filtered_dfs = []\n",
    "\n",
    "data = [\n",
    "  (cumulative_1, '31/10/2008'),\n",
    "  (cumulative_2, '03/01/2009'),\n",
    "  (cumulative_3, '22/05/2010'),\n",
    "  (cumulative_4, '29/11/2013'),\n",
    "  (cumulative_5, '17/12/2017'),\n",
    "  (cumulative_6, '15/12/2018'),\n",
    "  (cumulative_7, '26/06/2019'),\n",
    "  (cumulative_8, '12/03/2020'),\n",
    "  (cumulative_9, '25/04/2021'),\n",
    "  (cumulative_10, '20/07/2021'),\n",
    "  (cumulative_11, '20/10/2021'),\n",
    "  (cumulative_12, '10/11/2021'),\n",
    "  (cumulative_13, '18/06/2022'),\n",
    "]\n",
    "\n",
    "for i, (df, date) in enumerate(data):\n",
    "  filtered_dfs.append(cum_hel(df, date))\n",
    "\n",
    "cumm_hel = pd.concat(filtered_dfs)\n",
    "hel = pd.concat([result, cumm_hel])\n",
    "hel = hel.round()\n",
    "\n",
    "hel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96efda86",
   "metadata": {},
   "outputs": [],
   "source": [
    "helio[helio.Date == today]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = helio[helio.Date == today]\n",
    "xx.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','helio.csv'), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = geo[geo.Date == today]\n",
    "xxx.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','geo.csv'), index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce61220",
   "metadata": {},
   "source": [
    "### **II.1.2 MOD30 & 360**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b83d92",
   "metadata": {},
   "source": [
    "#### **MOD30**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod30 (donne qu'elle signe il est)\n",
    "\n",
    "mod = pd.DataFrame({'Date': [today],\n",
    "\n",
    "                                       'Earth': helio['Earth'][helio.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                       'Mer': helio['Mer'][helio.Date == today].values\n",
    "                                       % 30,\n",
    "                                       \n",
    "                                       'Ven': helio['Ven'][helio.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                       'Mar': helio['Mar'][helio.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                       'Jup': helio['Jup'][helio.Date == today].values\n",
    "                                       % 30,\n",
    "                                       \n",
    "                                       'Sat': helio['Sat'][helio.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                       'Ura': helio['Ura'][helio.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                       'Nep': helio['Nep'][helio.Date == today].values\n",
    "                                       % 30,\n",
    "                                       \n",
    "                                       'Plu': helio['Plu'][helio.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                       })\n",
    "\n",
    "\n",
    "mod = mod.round()\n",
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ea04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rrr\n",
    "\n",
    "result2 = result.copy() # rrr\n",
    "\n",
    "for col in result2.columns[1:]:\n",
    "     result2= result2.astype({col: \"int64\"})\n",
    "\n",
    "for col in result2.columns[1:]:\n",
    "     result2= result2.astype({col: \"int64\"})\n",
    "\n",
    "rrr = pd.DataFrame({'Date': [today],\n",
    "\n",
    "                                       'Earth': helio['Earth'][helio.Date == today].values,\n",
    "\n",
    "                                       'Mer': helio['Mer'][helio.Date == today].values,\n",
    "                                       \n",
    "                                       'Ven': helio['Ven'][helio.Date == today].values,\n",
    "\n",
    "                                       'Mar': helio['Mar'][helio.Date == today].values,\n",
    "\n",
    "                                       'Jup': helio['Jup'][helio.Date == today].values,\n",
    "                                       \n",
    "                                       'Sat': helio['Sat'][helio.Date == today].values,\n",
    "\n",
    "                                       'Ura': helio['Ura'][helio.Date == today].values,\n",
    "\n",
    "                                       'Nep': helio['Nep'][helio.Date == today].values,\n",
    "                                       \n",
    "                                       'Plu': helio['Plu'][helio.Date == today].values,\n",
    "\n",
    "                                       })\n",
    "\n",
    "rrr.round()\n",
    "\n",
    "for i in rrr['Earth']: \n",
    "        if (0<=i<=29):\n",
    "            rrr['Earth'] = rrr['Earth'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr['Earth'] = rrr['Earth'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr['Earth'] = rrr['Earth'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr['Earth'] = rrr['Earth'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr['Earth'] = rrr['Earth'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr['Earth'] = rrr['Earth'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr['Earth'] = rrr['Earth'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr['Earth'] = rrr['Earth'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr['Earth'] = rrr['Earth'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr['Earth'] = rrr['Earth'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr['Earth'] = rrr['Earth'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr['Earth'] = rrr['Earth'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr['Mer']: \n",
    "        if (0<=i<=29):\n",
    "            rrr['Mer'] = rrr['Mer'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr['Mer'] = rrr['Mer'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr['Mer'] = rrr['Mer'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr['Mer'] = rrr['Mer'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr['Mer'] = rrr['Mer'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr['Mer'] = rrr['Mer'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr['Mer'] = rrr['Mer'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr['Mer'] = rrr['Mer'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr['Mer'] = rrr['Mer'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr['Mer'] = rrr['Mer'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr['Mer'] = rrr['Mer'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr['Mer'] = rrr['Mer'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr['Ven']: \n",
    "        if (0<=i<=29):\n",
    "            rrr['Ven'] = rrr['Ven'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr['Ven'] = rrr['Ven'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr['Ven'] = rrr['Ven'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr['Ven'] = rrr['Ven'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr['Ven'] = rrr['Ven'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr['Ven'] = rrr['Ven'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr['Ven'] = rrr['Ven'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr['Ven'] = rrr['Ven'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr['Ven'] = rrr['Ven'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr['Ven'] = rrr['Ven'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr['Ven'] = rrr['Ven'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr['Ven'] = rrr['Ven'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr['Mar']: \n",
    "        if (0<=i<=29):\n",
    "            rrr['Mar'] = rrr['Mar'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr['Mar'] = rrr['Mar'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr['Mar'] = rrr['Mar'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr['Mar'] = rrr['Mar'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr['Mar'] = rrr['Mar'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr['Mar'] = rrr['Mar'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr['Mar'] = rrr['Mar'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr['Mar'] = rrr['Mar'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr['Mar'] = rrr['Mar'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr['Mar'] = rrr['Mar'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr['Mar'] = rrr['Mar'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr['Mar'] = rrr['Mar'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr['Jup']: \n",
    "        if (0<=i<=29):\n",
    "            rrr['Jup'] = rrr['Jup'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr['Jup'] = rrr['Jup'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr['Jup'] = rrr['Jup'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr['Jup'] = rrr['Jup'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr['Jup'] = rrr['Jup'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr['Jup'] = rrr['Jup'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr['Jup'] = rrr['Jup'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr['Jup'] = rrr['Jup'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr['Jup'] = rrr['Jup'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr['Jup'] = rrr['Jup'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr['Jup'] = rrr['Jup'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=360):\n",
    "            rrr['Jup'] = rrr['Jup'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr['Sat']: \n",
    "        if (0<=i<=29):\n",
    "            rrr['Sat'] = rrr['Sat'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr['Sat'] = rrr['Sat'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr['Sat'] = rrr['Sat'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr['Sat'] = rrr['Sat'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr['Sat'] = rrr['Sat'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr['Sat'] = rrr['Sat'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr['Sat'] = rrr['Sat'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr['Sat'] = rrr['Sat'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr['Sat'] = rrr['Sat'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr['Sat'] = rrr['Sat'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr['Sat'] = rrr['Sat'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr['Sat'] = rrr['Sat'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr['Ura']: \n",
    "        if (0<=i<=29):\n",
    "            rrr['Ura'] = rrr['Ura'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr['Ura'] = rrr['Ura'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr['Ura'] = rrr['Ura'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr['Ura'] = rrr['Ura'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr['Ura'] = rrr['Ura'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr['Ura'] = rrr['Ura'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr['Ura'] = rrr['Ura'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr['Ura'] = rrr['Ura'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr['Ura'] = rrr['Ura'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr['Ura'] = rrr['Ura'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr['Ura'] = rrr['Ura'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=360):\n",
    "            rrr['Ura'] = rrr['Ura'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr['Nep']: \n",
    "        if (0<=i<=29):\n",
    "            rrr['Nep'] = rrr['Nep'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr['Nep'] = rrr['Nep'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr['Nep'] = rrr['Nep'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr['Nep'] = rrr['Nep'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr['Nep'] = rrr['Nep'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr['Nep'] = rrr['Nep'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr['Nep'] = rrr['Nep'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr['Nep'] = rrr['Nep'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr['Nep'] = rrr['Nep'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr['Nep'] = rrr['Nep'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr['Nep'] = rrr['Nep'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=360):\n",
    "            rrr['Nep'] = rrr['Nep'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr['Plu']: \n",
    "        if (0<=i<=29):\n",
    "            rrr['Plu'] = rrr['Plu'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr['Plu'] = rrr['Plu'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr['Plu'] = rrr['Plu'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr['Plu'] = rrr['Plu'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr['Plu'] = rrr['Plu'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr['Plu'] = rrr['Plu'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr['Plu'] = rrr['Plu'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr['Plu'] = rrr['Plu'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr['Plu'] = rrr['Plu'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr['Plu'] = rrr['Plu'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr['Plu'] = rrr['Plu'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr['Plu'] = rrr['Plu'].replace(i, \"Pi\")\n",
    "\n",
    "rrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c8b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = mod.round()\n",
    "\n",
    "# STR\n",
    "\n",
    "for col in mod.columns[1:]:\n",
    "     mod = mod.astype({col: str})\n",
    "\n",
    "for col in rrr.columns[1:]:\n",
    "     rrr = rrr.astype({col: str})\n",
    "\n",
    "mod0 = pd.DataFrame({\"Date\": [today]})\n",
    "\n",
    "# GROUPBY MANUALY\n",
    "\n",
    "for col in mod.columns[1:]:\n",
    "    mod0[col] = mod[col] + ' | ' + rrr[col] #.groupby('Date').agg('-'.join).reset_index()\n",
    "    \n",
    "mod0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b7bff5",
   "metadata": {},
   "source": [
    "#### **MOD360**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef9805",
   "metadata": {},
   "outputs": [],
   "source": [
    "revgui = hel.copy()\n",
    "\n",
    "revgui['Earth'] = revgui['Earth'] / 360\n",
    "revgui['Mer'] = revgui['Mer'] / 360\n",
    "revgui['Ven'] = revgui['Ven'] / 360\n",
    "revgui['Mar'] = revgui['Mar'] / 360\n",
    "revgui['Jup'] = revgui['Jup'] / 360\n",
    "revgui['Sat'] = revgui['Sat'] / 360\n",
    "revgui['Nep'] = revgui['Nep'] / 360\n",
    "revgui['Plu'] = revgui['Plu'] / 360\n",
    "\n",
    "revgui = revgui.iloc[::, revgui.columns !='Date'].apply(np.floor)\n",
    "\n",
    "revgui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6828307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BON CUM MOD/REV\n",
    "\n",
    "hexx = hel.copy()\n",
    "\n",
    "hexx['Earth'] = hexx['Earth'] / 360\n",
    "hexx['Mer'] = hexx['Mer'] / 360\n",
    "hexx['Ven'] = hexx['Ven'] / 360\n",
    "hexx['Mar'] = hexx['Mar'] / 360\n",
    "hexx['Jup'] = hexx['Jup'] / 360\n",
    "hexx['Sat'] = hexx['Sat'] / 360\n",
    "hexx['Nep'] = hexx['Nep'] / 360\n",
    "hexx['Plu'] = hexx['Plu'] / 360\n",
    "\n",
    "hecc = hel.copy()\n",
    "\n",
    "hecc['Earth'] = hecc['Earth'] % 360\n",
    "hecc['Mer'] = hecc['Mer'] % 360\n",
    "hecc['Ven'] = hecc['Ven'] % 360\n",
    "hecc['Mar'] = hecc['Mar'] % 360\n",
    "hecc['Jup'] = hecc['Jup'] % 360\n",
    "hecc['Sat'] = hecc['Sat'] % 360\n",
    "hecc['Nep'] = hecc['Nep'] % 360\n",
    "hecc['Plu'] = hecc['Plu'] % 360\n",
    "\n",
    "hexx = hexx.iloc[1: , :]\n",
    "hecc = hecc.iloc[1:, :]\n",
    "\n",
    "# ROUNDDOWN\n",
    "\n",
    "hexx = hexx.iloc[::, hexx.columns !='Date'].apply(np.floor)\n",
    "hecc = hecc.iloc[::, hecc.columns !='Date'].apply(np.floor)\n",
    "\n",
    "# STR\n",
    "\n",
    "for col in hexx.columns[::]:\n",
    "     hexx = hexx.astype({col: str})\n",
    "\n",
    "for col in hecc.columns[::]:\n",
    "     hecc = hecc.astype({col: str})\n",
    "\n",
    "puant = pd.DataFrame({\"Date\": cumm_hel['Date']})\n",
    "\n",
    "# GROUPBY MANUALY\n",
    "\n",
    "for col in hexx.columns[::]:\n",
    "    puant[col] = hexx[col] + ' | ' + hecc[col] #.groupby('Date').agg('-'.join).reset_index()\n",
    "    \n",
    "puant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efebd3",
   "metadata": {},
   "source": [
    "### **II.1.3 CONCAT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe495b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "helio_concat = pd.concat([cumm_hel, puant], axis=0)\n",
    "helio_concat.Date = pd.to_datetime(helio_concat.Date)\n",
    "helio_concat = helio_concat.sort_values(\"Date\", ignore_index=True)\n",
    "helio_concat.Date = helio_concat.Date.dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "hcc = pd.concat([result, mod0, helio_concat])\n",
    "hcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f03c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hcc.round(2).to_csv(os.path.join('STREAMLIT//data//test','helio_main.csv'), index = False, float_format = '%2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8713dd",
   "metadata": {},
   "source": [
    "## **II.2 GEO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26bea0a",
   "metadata": {},
   "source": [
    "### **II.2.1 CUMUL GEO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddfda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = datetime.strftime(datetime.now(), \"%d/%m/%Y\")\n",
    "\n",
    "cumulative_1 = geo_cum.copy()\n",
    "cumulative_2 = geo_cum.copy()\n",
    "cumulative_3 = geo_cum.copy()\n",
    "cumulative_4 = geo_cum.copy()\n",
    "cumulative_5 = geo_cum.copy()\n",
    "cumulative_6 = geo_cum.copy()\n",
    "cumulative_7 = geo_cum.copy()\n",
    "cumulative_8 = geo_cum.copy()\n",
    "cumulative_9 = geo_cum.copy()\n",
    "cumulative_10 = geo_cum.copy()\n",
    "cumulative_11 = geo_cum.copy()\n",
    "cumulative_12 = geo_cum.copy()\n",
    "cumulative_13 = geo_cum.copy()\n",
    "\n",
    "geo = geo.copy()\n",
    "result_g = geo[geo.Date == today]\n",
    "\n",
    "def cum_geo(df, date):\n",
    "    today = datetime.strftime(datetime.now(), \"%d/%m/%Y\")\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"Date\": [date],\n",
    "            \"Moon\": df[\"Moon\"][df.Date == today].values\n",
    "            - df[\"Moon\"][df.Date == date].values,\n",
    "            \"Sun\": df[\"Sun\"][df.Date == today].values\n",
    "            - df[\"Sun\"][df.Date == date].values,\n",
    "            \"Mer\": df[\"Mer\"][df.Date == today].values\n",
    "            - df[\"Mer\"][df.Date == date].values,\n",
    "            \"Ven\": df[\"Ven\"][df.Date == today].values\n",
    "            - df[\"Ven\"][df.Date == date].values,\n",
    "            \"Mar\": df[\"Mar\"][df.Date == today].values\n",
    "            - df[\"Mar\"][df.Date == date].values,\n",
    "            \"Jup\": df[\"Jup\"][df.Date == today].values\n",
    "            - df[\"Jup\"][df.Date == date].values,\n",
    "            \"Sat\": df[\"Sat\"][df.Date == today].values\n",
    "            - df[\"Sat\"][df.Date == date].values,\n",
    "            \"Ura\": df[\"Ura\"][df.Date == today].values\n",
    "            - df[\"Ura\"][df.Date == date].values,\n",
    "            \"Nep\": df[\"Nep\"][df.Date == today].values\n",
    "            - df[\"Nep\"][df.Date == date].values,\n",
    "            \"Plu\": df[\"Plu\"][df.Date == today].values\n",
    "            - df[\"Plu\"][df.Date == date].values,\n",
    "        }\n",
    "    )\n",
    "\n",
    "filtered_dfs = []\n",
    "\n",
    "data = [\n",
    "  (cumulative_1, '31/10/2008'),\n",
    "  (cumulative_2, '03/01/2009'),\n",
    "  (cumulative_3, '22/05/2010'),\n",
    "  (cumulative_4, '29/11/2013'),\n",
    "  (cumulative_5, '17/12/2017'),\n",
    "  (cumulative_6, '15/12/2018'),\n",
    "  (cumulative_7, '26/06/2019'),\n",
    "  (cumulative_8, '12/03/2020'),\n",
    "  (cumulative_9, '25/04/2021'),\n",
    "  (cumulative_10, '20/07/2021'),\n",
    "  (cumulative_11, '20/10/2021'),\n",
    "  (cumulative_12, '10/11/2021'),\n",
    "  (cumulative_13, '18/06/2022'),\n",
    "]\n",
    "\n",
    "for i, (df, date) in enumerate(data):\n",
    "  filtered_dfs.append(cum_geo(df, date))\n",
    "\n",
    "cumm_geo = pd.concat(filtered_dfs)\n",
    "geol = pd.concat([result_g, cumm_geo])\n",
    "geol = geol.round()\n",
    "\n",
    "geol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785cfdc1",
   "metadata": {},
   "source": [
    "### **II.2.2 MOD30 & 360 GEO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b83d92",
   "metadata": {},
   "source": [
    "#### **MOD30**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod30 (donne qu'elle signe il est)\n",
    "\n",
    "mod_g = pd.DataFrame({'Date': [today],\n",
    "\n",
    "                                       'Moon': result_g['Moon'][result_g.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                        'Sun': result_g['Sun'][result_g.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                       'Mer': result_g['Mer'][result_g.Date == today].values\n",
    "                                       % 30,\n",
    "                                       \n",
    "                                       'Ven': result_g['Ven'][result_g.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                       'Mar': result_g['Mar'][result_g.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                       'Jup': result_g['Jup'][result_g.Date == today].values\n",
    "                                       % 30,\n",
    "                                       \n",
    "                                       'Sat': result_g['Sat'][result_g.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                       'Ura': result_g['Ura'][result_g.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                       'Nep': result_g['Nep'][result_g.Date == today].values\n",
    "                                       % 30,\n",
    "                                       \n",
    "                                       'Plu': result_g['Plu'][result_g.Date == today].values\n",
    "                                       % 30,\n",
    "\n",
    "                                       })\n",
    "\n",
    "mod_g.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ea04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rrr\n",
    "\n",
    "# mod30 (donne qu'elle signe il est)\n",
    "\n",
    "rrr_g = result_g.copy() # rrr\n",
    "\n",
    "for col in rrr_g.columns[1:]:\n",
    "     rrr_g= rrr_g.astype({col: \"int64\"})\n",
    "\n",
    "rrr_g = pd.DataFrame({'Date': [today],\n",
    "\n",
    "                                       'Moon': rrr_g['Moon'][rrr_g.Date == today].values\n",
    "                                       ,\n",
    "\n",
    "                                        'Sun': rrr_g['Sun'][rrr_g.Date == today].values\n",
    "                                       ,\n",
    "\n",
    "                                       'Mer': rrr_g['Mer'][rrr_g.Date == today].values\n",
    "                                       ,\n",
    "                                       \n",
    "                                       'Ven': rrr_g['Ven'][rrr_g.Date == today].values\n",
    "                                       ,\n",
    "\n",
    "                                       'Mar': rrr_g['Mar'][rrr_g.Date == today].values\n",
    "                                       ,\n",
    "\n",
    "                                       'Jup': rrr_g['Jup'][rrr_g.Date == today].values\n",
    "                                       ,\n",
    "                                       \n",
    "                                       'Sat': rrr_g['Sat'][rrr_g.Date == today].values\n",
    "                                       ,\n",
    "\n",
    "                                       'Ura': rrr_g['Ura'][rrr_g.Date == today].values\n",
    "                                       ,\n",
    "\n",
    "                                       'Nep': rrr_g['Nep'][rrr_g.Date == today].values\n",
    "                                       ,\n",
    "                                       \n",
    "                                       'Plu': rrr_g['Plu'][rrr_g.Date == today].values\n",
    "                                       ,\n",
    "\n",
    "                                       })\n",
    "\n",
    "rrr_g.round()\n",
    "\n",
    "for i in rrr_g['Moon']: \n",
    "        if (0<=i<=29):\n",
    "            rrr_g['Moon'] = rrr_g['Moon'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr_g['Moon'] = rrr_g['Moon'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr_g['Moon'] = rrr_g['Moon'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr_g['Moon'] = rrr_g['Moon'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr_g['Moon'] = rrr_g['Moon'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr_g['Moon'] = rrr_g['Moon'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr_g['Moon'] = rrr_g['Moon'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr_g['Moon'] = rrr_g['Moon'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr_g['Moon'] = rrr_g['Moon'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr_g['Moon'] = rrr_g['Moon'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr_g['Moon'] = rrr_g['Moon'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr_g['Moon'] = rrr_g['Moon'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr_g['Sun']: \n",
    "        if (0<=i<=29):\n",
    "            rrr_g['Sun'] = rrr_g['Sun'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr_g['Sun'] = rrr_g['Sun'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr_g['Sun'] = rrr_g['Sun'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr_g['Sun'] = rrr_g['Sun'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr_g['Sun'] = rrr_g['Sun'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr_g['Sun'] = rrr_g['Sun'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr_g['Sun'] = rrr_g['Sun'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr_g['Sun'] = rrr_g['Sun'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr_g['Sun'] = rrr_g['Sun'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr_g['Sun'] = rrr_g['Sun'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr_g['Sun'] = rrr_g['Sun'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr_g['Sun'] = rrr_g['Sun'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr_g['Mer']: \n",
    "        if (0<=i<=29):\n",
    "            rrr_g['Mer'] = rrr_g['Mer'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr_g['Mer'] = rrr_g['Mer'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr_g['Mer'] = rrr_g['Mer'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr_g['Mer'] = rrr_g['Mer'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr_g['Mer'] = rrr_g['Mer'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr_g['Mer'] = rrr_g['Mer'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr_g['Mer'] = rrr_g['Mer'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr_g['Mer'] = rrr_g['Mer'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr_g['Mer'] = rrr_g['Mer'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr_g['Mer'] = rrr_g['Mer'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr_g['Mer'] = rrr_g['Mer'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr_g['Mer'] = rrr_g['Mer'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr_g['Ven']: \n",
    "        if (0<=i<=29):\n",
    "            rrr_g['Ven'] = rrr_g['Ven'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr_g['Ven'] = rrr_g['Ven'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr_g['Ven'] = rrr_g['Ven'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr_g['Ven'] = rrr_g['Ven'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr_g['Ven'] = rrr_g['Ven'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr_g['Ven'] = rrr_g['Ven'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr_g['Ven'] = rrr_g['Ven'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr_g['Ven'] = rrr_g['Ven'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr_g['Ven'] = rrr_g['Ven'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr_g['Ven'] = rrr_g['Ven'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr_g['Ven'] = rrr_g['Ven'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr_g['Ven'] = rrr_g['Ven'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr_g['Mar']: \n",
    "        if (0<=i<=29):\n",
    "            rrr_g['Mar'] = rrr_g['Mar'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr_g['Mar'] = rrr_g['Mar'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr_g['Mar'] = rrr_g['Mar'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr_g['Mar'] = rrr_g['Mar'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr_g['Mar'] = rrr_g['Mar'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr_g['Mar'] = rrr_g['Mar'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr_g['Mar'] = rrr_g['Mar'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr_g['Mar'] = rrr_g['Mar'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr_g['Mar'] = rrr_g['Mar'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr_g['Mar'] = rrr_g['Mar'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr_g['Mar'] = rrr_g['Mar'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr_g['Mar'] = rrr_g['Mar'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr_g['Jup']: \n",
    "        if (0<=i<=29):\n",
    "            rrr_g['Jup'] = rrr_g['Jup'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr_g['Jup'] = rrr_g['Jup'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr_g['Jup'] = rrr_g['Jup'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr_g['Jup'] = rrr_g['Jup'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr_g['Jup'] = rrr_g['Jup'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr_g['Jup'] = rrr_g['Jup'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr_g['Jup'] = rrr_g['Jup'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr_g['Jup'] = rrr_g['Jup'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr_g['Jup'] = rrr_g['Jup'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr_g['Jup'] = rrr_g['Jup'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr_g['Jup'] = rrr_g['Jup'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr_g['Jup'] = rrr_g['Jup'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr_g['Sat']: \n",
    "        if (0<=i<=29):\n",
    "            rrr_g['Sat'] = rrr_g['Sat'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr_g['Sat'] = rrr_g['Sat'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr_g['Sat'] = rrr_g['Sat'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr_g['Sat'] = rrr_g['Sat'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr_g['Sat'] = rrr_g['Sat'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr_g['Sat'] = rrr_g['Sat'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr_g['Sat'] = rrr_g['Sat'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr_g['Sat'] = rrr_g['Sat'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr_g['Sat'] = rrr_g['Sat'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr_g['Sat'] = rrr_g['Sat'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr_g['Sat'] = rrr_g['Sat'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr_g['Sat'] = rrr_g['Sat'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr_g['Ura']: \n",
    "        if (0<=i<=29):\n",
    "            rrr_g['Ura'] = rrr_g['Ura'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr_g['Ura'] = rrr_g['Ura'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr_g['Ura'] = rrr_g['Ura'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr_g['Ura'] = rrr_g['Ura'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr_g['Ura'] = rrr_g['Ura'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr_g['Ura'] = rrr_g['Ura'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr_g['Ura'] = rrr_g['Ura'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr_g['Ura'] = rrr_g['Ura'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr_g['Ura'] = rrr_g['Ura'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr_g['Ura'] = rrr_g['Ura'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr_g['Ura'] = rrr_g['Ura'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr_g['Ura'] = rrr_g['Ura'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr_g['Nep']: \n",
    "        if (0<=i<=29):\n",
    "            rrr_g['Nep'] = rrr_g['Nep'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr_g['Nep'] = rrr_g['Nep'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr_g['Nep'] = rrr_g['Nep'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr_g['Nep'] = rrr_g['Nep'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr_g['Nep'] = rrr_g['Nep'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr_g['Nep'] = rrr_g['Nep'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr_g['Nep'] = rrr_g['Nep'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr_g['Nep'] = rrr_g['Nep'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr_g['Nep'] = rrr_g['Nep'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr_g['Nep'] = rrr_g['Nep'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr_g['Nep'] = rrr_g['Nep'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr_g['Nep'] = rrr_g['Nep'].replace(i, \"Pi\")\n",
    "\n",
    "for i in rrr_g['Plu']: \n",
    "        if (0<=i<=29):\n",
    "            rrr_g['Plu'] = rrr_g['Plu'].replace(i, \"Ar\")\n",
    "        elif (30<=i<=59):\n",
    "            rrr_g['Plu'] = rrr_g['Plu'].replace(i, \"Ta\")\n",
    "        elif (60<=i<=89):\n",
    "            rrr_g['Plu'] = rrr_g['Plu'].replace(i, \"Ge\")\n",
    "        elif (90<=i<=119):\n",
    "            rrr_g['Plu'] = rrr_g['Plu'].replace(i, \"Ca\")\n",
    "        elif (120<=i<=149):\n",
    "            rrr_g['Plu'] = rrr_g['Plu'].replace(i, \"Le\")\n",
    "        elif (150<=i<=179):\n",
    "            rrr_g['Plu'] = rrr_g['Plu'].replace(i, \"Vi\")\n",
    "        elif (180<=i<=209):\n",
    "            rrr_g['Plu'] = rrr_g['Plu'].replace(i, \"Li\")\n",
    "        elif (209<=i<=239):\n",
    "            rrr_g['Plu'] = rrr_g['Plu'].replace(i, \"Sc\")\n",
    "        elif (240<=i<=269):\n",
    "            rrr_g['Plu'] = rrr_g['Plu'].replace(i, \"Sg\")\n",
    "        elif (270<=i<=299):\n",
    "            rrr_g['Plu'] = rrr_g['Plu'].replace(i, \"Cp\")\n",
    "        elif (300<=i<=329):\n",
    "            rrr_g['Plu'] = rrr_g['Plu'].replace(i, \"Aq\")\n",
    "        elif (330<=i<=359):\n",
    "            rrr_g['Plu'] = rrr_g['Plu'].replace(i, \"Pi\")\n",
    "\n",
    "rrr_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c8b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_g = mod_g.round()\n",
    "\n",
    "# STR\n",
    "\n",
    "for col in mod_g.columns[1:]:\n",
    "     mod_g = mod_g.astype({col: str})\n",
    "\n",
    "for col in rrr_g.columns[1:]:\n",
    "     rrr_g = rrr_g.astype({col: str})\n",
    "\n",
    "mod0_g = pd.DataFrame({\"Date\": [today]})\n",
    "\n",
    "# GROUPBY MANUALY\n",
    "\n",
    "for col in mod_g.columns[1:]:\n",
    "    mod0_g[col] = mod_g[col] + ' | ' + rrr_g[col] #.groupby('Date').agg('-'.join).reset_index()\n",
    "    \n",
    "mod0_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b7bff5",
   "metadata": {},
   "source": [
    "#### **MOD360**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BON CUM MOD/REV\n",
    "\n",
    "gexx = geol.copy()\n",
    "\n",
    "gexx['Moon'] = gexx['Moon'] / 360\n",
    "gexx['Sun'] = gexx['Sun'] / 360\n",
    "gexx['Mer'] = gexx['Mer'] / 360\n",
    "gexx['Ven'] = gexx['Ven'] / 360\n",
    "gexx['Mar'] = gexx['Mar'] / 360\n",
    "gexx['Jup'] = gexx['Jup'] / 360\n",
    "gexx['Sat'] = gexx['Sat'] / 360\n",
    "gexx['Nep'] = gexx['Nep'] / 360\n",
    "gexx['Plu'] = gexx['Plu'] / 360\n",
    "\n",
    "gecc = geol.copy()\n",
    "\n",
    "gecc['Moon'] = gecc['Moon'] % 360\n",
    "gecc['Sun'] = gecc['Sun'] % 360\n",
    "gecc['Mer'] = gecc['Mer'] % 360\n",
    "gecc['Ven'] = gecc['Ven'] % 360\n",
    "gecc['Mar'] = gecc['Mar'] % 360\n",
    "gecc['Jup'] = gecc['Jup'] % 360\n",
    "gecc['Sat'] = gecc['Sat'] % 360\n",
    "gecc['Nep'] = gecc['Nep'] % 360\n",
    "gecc['Plu'] = gecc['Plu'] % 360\n",
    "\n",
    "gexx = gexx.iloc[1: , :]\n",
    "gecc = gecc.iloc[1:, :]\n",
    "\n",
    "# ROUNDDOWN\n",
    "\n",
    "gexx = gexx.iloc[::, gexx.columns !='Date'].apply(np.floor)\n",
    "gecc = gecc.iloc[::, gecc.columns !='Date'].apply(np.floor)\n",
    "\n",
    "# STR\n",
    "\n",
    "for col in gexx.columns[::]:\n",
    "     gexx = gexx.astype({col: str})\n",
    "\n",
    "for col in gecc.columns[::]:\n",
    "     gecc = gecc.astype({col: str})\n",
    "\n",
    "puant_g = pd.DataFrame({\"Date\": cumm_hel['Date']})\n",
    "\n",
    "# GROUPBY MANUALY\n",
    "\n",
    "for col in gexx.columns[::]:\n",
    "    puant_g[col] = gexx[col] + ' | ' + gecc[col] #.groupby('Date').agg('-'.join).reset_index()\n",
    "    \n",
    "puant_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5209d",
   "metadata": {},
   "source": [
    "### **II.2.3 CONCAT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5954caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_concat = pd.concat([cumm_geo, puant_g], axis=0)\n",
    "geo_concat.Date = pd.to_datetime(geo_concat.Date)\n",
    "geo_concat = geo_concat.sort_values(\"Date\", ignore_index=True)\n",
    "geo_concat.Date = geo_concat.Date.dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "gcc = pd.concat([result_g, mod0_g, geo_concat])\n",
    "#gcc.to_csv(os.path.join('STREAMLIT//data//test','geo_main.csv'), index = False, float_format = '%2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95caa79d",
   "metadata": {},
   "source": [
    "# **III. ASPECTS TABLE & TOOLS.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246886e",
   "metadata": {},
   "source": [
    "### **III.1 Aspects H/G TrTr & TrNa**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485de1e",
   "metadata": {},
   "source": [
    "#### **III.1.1 HELIO TrTr & TrNa**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48277e",
   "metadata": {},
   "source": [
    "#### **inner code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef82dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELIO ASPECT TrTr - MADE BY US AUTOMATICALY FINDS INTO DATA\n",
    "\n",
    "#ha = helio_asp\n",
    "#col = []\n",
    "#cols = ha.columns[1:]\n",
    "#df = ha[cols]\n",
    "#Date = list[ha['Date']]\n",
    "\n",
    "#for columns in df.columns:\n",
    "\n",
    "    #globals()[\"liste_%s\"%columns] = []\n",
    "\n",
    "    #for row, i in enumerate(df[columns]):\n",
    "        #if (i >= 0 and i <= 0.03) or (i >= 3.75 and i <= 3.755) or (i >= 7.5 and i <= 7.55) or (i >= 15 and i <= 15.15) or (i >= 22.5 and i <= 22.55) or (i >= 30 and i <= 30.15) or (i >= 36 and i <= 36.15) or (i >= 45 and i <= 45.15) or (i >= 60 and i <= 60.15) or (i >= 72 and i <= 72.15) or (i >= 90 and i <= 90.15) or (i >= 120 and i <= 120.15) or (i >= 135 and i <= 135.15) or (i >= 144 and i <= 144.15) or (i >= 150 and i <= 150.15) or (i >= 180 and i <= 180.15):\n",
    "            #globals()[\"liste_%s\"%columns].append(i)\n",
    "        #else:\n",
    "            #globals()[\"liste_%s\"%columns].append(\" \")\n",
    "\n",
    "#flu = helio_asp[['Date']].copy()\n",
    "#dict = {'Sun_Mer': liste_Sun_Mer, 'Sun_Ven': liste_Sun_Ven, 'Sun_Mar': liste_Sun_Mar, 'Sun_Jup': liste_Sun_Jup, 'Sun_Sat': liste_Sun_Sat, 'Sun_Ura': liste_Sun_Ura, 'Sun_Nep': liste_Sun_Nep, 'Sun_Plu': liste_Sun_Plu, 'Mer_Ven': liste_Mer_Ven, 'Mer_Mar': liste_Mer_Mar, 'Mer_Jup': liste_Mer_Jup, 'Mer_Sat': liste_Mer_Sat, 'Mer_Ura': liste_Mer_Ura, 'Mer_Nep': liste_Mer_Nep, 'Mer_Plu': liste_Mer_Plu, 'Ven_Mar': liste_Ven_Mar, 'Ven_Jup': liste_Ven_Jup, 'Ven_Sat': liste_Ven_Sat, 'Ven_Ura': liste_Ven_Ura, 'Ven_Nep': liste_Ven_Nep, 'Ven_Plu': liste_Ven_Plu, 'Mar_Jup': liste_Mar_Jup, 'Mar_Sat': liste_Mar_Sat, 'Mar_Ura': liste_Mar_Ura, 'Mar_Nep': liste_Mar_Nep, 'Mar_Plu': liste_Mar_Plu, 'Jup_Sat': liste_Jup_Sat, 'Jup_Ura': liste_Jup_Ura, 'Jup_Nep': liste_Jup_Nep, 'Jup_Plu': liste_Jup_Plu, 'Sat_Ura': liste_Sat_Ura, 'Sat_Nep': liste_Sat_Nep, 'Sat_Plu': liste_Sat_Plu, 'Ura_Nep': liste_Ura_Nep, 'Ura_Plu': liste_Ura_Plu, 'Nep_Plu': liste_Nep_Plu} \n",
    "#dfObj = pd.DataFrame(dict)\n",
    "#flu = helio_asp[['Date']].copy()\n",
    "#concat_asp = pd.concat([flu, dfObj], axis=1)\n",
    "\n",
    "#asp_con = concat_asp[concat_asp.Date == today]\n",
    "#asp_con.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c36a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = points_tr.copy()\n",
    "\n",
    "b.fillna(0, inplace=True)\n",
    "\n",
    "b_h = b[b[\"Type\"] == \"Helio\"]\n",
    "b_g = b[b[\"Type\"] == \"Geo\"]\n",
    "\n",
    "b_h = b_h.drop(['Type'], axis = 1)\n",
    "b_g = b_g.drop(['Type'], axis = 1)\n",
    "b_con = pd.concat([b_h, b_g])\n",
    "\n",
    "b_con['Date'] = pd.to_datetime(b_con['Date'])  \n",
    "\n",
    "start_date = t  - timedelta(days = 1)\n",
    "end_date = t + timedelta(days = 3)\n",
    "\n",
    "mask = (b_con['Date'] > start_date) & (b_con['Date'] <= end_date)\n",
    "b_hits = b_con.loc[mask]\n",
    "b_hits = b_hits.sort_values(by=['Date'], ascending = True)\n",
    "b_trtr = b_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = points_na.copy()\n",
    "\n",
    "x.fillna(0, inplace=True)\n",
    "\n",
    "x_h = x[x[\"Type\"] == \"Helio\"]\n",
    "x_g = x[x[\"Type\"] == \"Geo\"]\n",
    "\n",
    "x_h = x_h.drop(['Type'], axis = 1)\n",
    "x_h = x_h.drop(['Angle'], axis = 1)\n",
    "x_h = x_h.drop(['Pair'], axis = 1)\n",
    "\n",
    "x_g = x_g.drop(['Type'], axis = 1)\n",
    "x_g = x_g.drop(['Angle'], axis = 1)\n",
    "x_g = x_g.drop(['Pair'], axis = 1)\n",
    "\n",
    "x_con = pd.concat([x_h, x_g])\n",
    "\n",
    "x_con['Date'] = pd.to_datetime(x_con['Date'])  \n",
    "start_date = t  - timedelta(days = 1)\n",
    "end_date = t + timedelta(days = 120)\n",
    "\n",
    "mask = (x_con['Date'] > start_date) & (x_con['Date'] <= end_date)\n",
    "\n",
    "x_hits = x_con.loc[mask]\n",
    "x_hits = x_hits.sort_values(by=['Date'], ascending = True)\n",
    "x_hi = x_con.loc[mask]\n",
    "x_hi = x_hi.sort_values(by=['Date'], ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dade97a",
   "metadata": {},
   "source": [
    "#### **result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f4b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(b_trtr, x=\"Date\", y=\"Points\", text=\"Points\", title=\"Aspects TrTr Points\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H_TrTr\n",
    "\n",
    "TrTr = TrTr.copy()\n",
    "helio_ap = TrTr[TrTr[\"Type\"] == \"Helio\"]\n",
    "helio_TrTr = helio_ap[helio_ap.Date == today]\n",
    "\n",
    "dz_TrTr_Asp = helio_TrTr\n",
    "dz_TrTr_Asp.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','aspects_h_tr.csv'), index= False)\n",
    "\n",
    "helio_TrTr.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76610896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H_TrNa\n",
    "\n",
    "TrNa = TrNa.copy()\n",
    "helio_TrNa = TrNa[TrNa[\"Type\"] == \"Helio\"]\n",
    "helio_TrNa = helio_TrNa[helio_TrNa.Date == today]\n",
    "\n",
    "dz_TrNa_Asp = helio_TrNa\n",
    "dz_TrNa_Asp.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','aspects_h_na.csv'), index= False)\n",
    "\n",
    "helio_TrNa.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2ccfb",
   "metadata": {},
   "source": [
    "#### **III.1.2 GEO TrTr & TrNa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(x_hi, x=\"Date\", y=\"Points\", text=\"Points\", title=\"Aspects TrNa Points\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bbf270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_TrTr\n",
    "\n",
    "geo_ap = TrTr[TrTr[\"Type\"] == \"Geo\"]\n",
    "geo_TrTr = geo_ap[geo_ap.Date == today]\n",
    "\n",
    "dz_Gtr_Asp = geo_TrTr\n",
    "dz_Gtr_Asp.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','aspects_g_tr.csv'), index= False)\n",
    "\n",
    "geo_TrTr.style.bar(subset=[\"Angle\"],color='Blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa91a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_TrNa\n",
    "\n",
    "geo_TrNa = TrNa[TrNa[\"Type\"] == \"Geo\"]\n",
    "geo_TrNa = geo_TrNa[geo_TrNa.Date == today]\n",
    "\n",
    "dz_Gna_Asp = geo_TrNa\n",
    "dz_Gna_Asp.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','aspects_g_na.csv'), index= False)\n",
    "\n",
    "geo_TrNa.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEO ASPECTS TrTr\n",
    "\n",
    "#ga = geo_asp_good\n",
    "\n",
    "#col = []\n",
    "#cols = ha.columns[1:]\n",
    "#df = ga[cols]\n",
    "#Date = list[ga['Date']]\n",
    "\n",
    "#for columns in df.columns:\n",
    "\n",
    "    #globals()[\"lizte_%s\"%columns] = []\n",
    "\n",
    "    #for row, i in enumerate(df[columns]):\n",
    "        #if (i >= 0 and i <= 0.03) or (i >= 3.75 and i <= 3.755) or (i >= 7.5 and i <= 7.59) or (i >= 15 and i <= 15.15) or (i >= 22.5 and i <= 22.55) or (i >= 30 and i <= 30.15) or (i >= 36 and i <= 36.15) or (i >= 45 and i <= 45.15) or (i >= 60 and i <= 60.15) or (i >= 72 and i <= 72.15) or (i >= 90 and i <= 90.15) or (i >= 120 and i <= 120.15) or (i >= 135 and i <= 135.15) or (i >= 144 and i <= 144.15) or (i >= 150 and i <= 150.15) or (i >= 180 and i <= 180.15):\n",
    "        #    globals()[\"lizte_%s\"%columns].append(i)\n",
    "        #else:\n",
    "          #  globals()[\"lizte_%s\"%columns].append(\" \")\n",
    "\n",
    "#flu1 = geo_asp_good[['Date']].copy()\n",
    "#dict = {'Sun_Mer': lizte_Sun_Mer, 'Sun_Ven': lizte_Sun_Ven, 'Sun_Mar': lizte_Sun_Mar, 'Sun_Jup': lizte_Sun_Jup, 'Sun_Sat': lizte_Sun_Sat, 'Sun_Ura': lizte_Sun_Ura, 'Sun_Nep': lizte_Sun_Nep, 'Sun_Plu': lizte_Sun_Plu, 'Mer_Ven': lizte_Mer_Ven, 'Mer_Mar': lizte_Mer_Mar, 'Mer_Jup': lizte_Mer_Jup, 'Mer_Sat': lizte_Mer_Sat, 'Mer_Ura': lizte_Mer_Ura, 'Mer_Nep': lizte_Mer_Nep, 'Mer_Plu': lizte_Mer_Plu, 'Ven_Mar': lizte_Ven_Mar, 'Ven_Jup': lizte_Ven_Jup, 'Ven_Sat': lizte_Ven_Sat, 'Ven_Ura': lizte_Ven_Ura, 'Ven_Nep': lizte_Ven_Nep, 'Ven_Plu': lizte_Ven_Plu, 'Mar_Jup': lizte_Mar_Jup, 'Mar_Sat': lizte_Mar_Sat, 'Mar_Ura': lizte_Mar_Ura, 'Mar_Nep': lizte_Mar_Nep, 'Mar_Plu': lizte_Mar_Plu, 'Jup_Sat': lizte_Jup_Sat, 'Jup_Ura': lizte_Jup_Ura, 'Jup_Nep': lizte_Jup_Nep, 'Jup_Plu': lizte_Jup_Plu, 'Sat_Ura': lizte_Sat_Ura, 'Sat_Nep': lizte_Sat_Nep, 'Sat_Plu': lizte_Sat_Plu, 'Ura_Nep': lizte_Ura_Nep, 'Ura_Plu': lizte_Ura_Plu, 'Nep_Plu': lizte_Nep_Plu}\n",
    "#dfObj = pd.DataFrame(dict)\n",
    "#concat_asp_g = pd.concat([flu1, dfObj], axis=1)\n",
    "\n",
    "#geo_con = concat_asp_g[concat_asp_g.Date == today]\n",
    "#geo_con.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24618374",
   "metadata": {},
   "source": [
    "### **III.2 Retro**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6afc04",
   "metadata": {},
   "source": [
    "*(0 = rien | 1 = RETRO | 2 = RETURN)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64fb1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the nan and fill the empty string\n",
    "retro = retro.copy()\n",
    "\n",
    "retro.fillna('')\n",
    "retro = retro.replace(np.nan,'',regex = True)\n",
    "\n",
    "dz_Retr = retro[retro.Date == today]\n",
    "dz_Retr.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','retro_asp.csv'), index= False)\n",
    "\n",
    "retro1 = retro[retro.Date == today]\n",
    "retro1.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b3cc72",
   "metadata": {},
   "source": [
    "### **III.3 Declinations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54be62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec_lat\n",
    "\n",
    "lat_moon_changes = lat_moon_changes.copy()\n",
    "\n",
    "dec_lat = pd.DataFrame({'Date': [today],\n",
    "\n",
    "                                       'Dec/Lat': lat_moon_changes['LatChanges'][lat_moon_changes.Date == today].values\n",
    "                                       + lat_moon_changes['MoonChanges'][lat_moon_changes.Date == today].values,\n",
    "\n",
    "                                       })\n",
    "\n",
    "dz_dec_lat = dec_lat[dec_lat.Date == today]\n",
    "dz_dec_lat.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','dec_lat.csv'), index= False)\n",
    "\n",
    "dec_lat.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91eebff",
   "metadata": {},
   "source": [
    "### **III.4 GEO TOOLS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b098fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEO TOOLS\n",
    "\n",
    "declinations = declinations.copy()\n",
    "latitudes = latitudes.copy()\n",
    "Moon = Moon.copy()\n",
    "planet_node = planet_node.copy()\n",
    "samedec_samelat = samedec_samelat.copy()\n",
    "\n",
    "tools_con = pd.concat([declinations, lat_moon_changes, latitudes, Moon, planet_node, samedec_samelat])\n",
    "\n",
    "tools = pd.DataFrame({'Date': [today],\n",
    "\n",
    "                                       'New Moon': Moon['NewMoon'][Moon.Date == today].values,\n",
    "\n",
    "                                       'Full Moon': Moon['FullMoon'][Moon.Date == today].values,\n",
    "\n",
    "                                       'Node': planet_node['Planet Node'][planet_node.Date == today].values,\n",
    "\n",
    "                                       'Same Dec': samedec_samelat['Same Dec'][samedec_samelat.Date == today].values,        \n",
    "\n",
    "                                       'Same Lat': samedec_samelat['Same Lat'][samedec_samelat.Date == today].values,\n",
    "\n",
    "                                       'Lat Changes': lat_moon_changes['LatChanges'][lat_moon_changes.Date == today].values,    \n",
    "\n",
    "                                       'Moon Changes': lat_moon_changes['MoonChanges'][lat_moon_changes.Date == today].values,\n",
    "\n",
    "                                       'Lat Changes': lat_moon_changes['LatChanges'][lat_moon_changes.Date == today].values,       \n",
    "                                                                                                             \n",
    "})\n",
    "\n",
    "tools.fillna('')\n",
    "tools = tools.replace(0, np.nan)\n",
    "tools = tools.replace(np.nan,'',regex = True)\n",
    "\n",
    "dz_tools = tools[tools.Date == today]\n",
    "dz_tools.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','tools.csv'), index= False)\n",
    "\n",
    "tools.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b42da3",
   "metadata": {},
   "source": [
    "# **IV. SPIRAL TAB.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdceb87a",
   "metadata": {},
   "source": [
    "## 1. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc2a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match every dates to cols\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "Spiral = Spiral.copy()\n",
    "\n",
    "for col in Spiral.columns[1:]:\n",
    "    Spiral[col] = ((pd.to_datetime(Spiral['Date']) + pd.to_timedelta(f'{col} days'))\n",
    "               .dt.strftime('%d/%m/%Y'))\n",
    "\n",
    "dx = Spiral[1:].unstack().value_counts(ascending=False)\n",
    "\n",
    "dx = pd.DataFrame(dx, columns=['Hit'])\n",
    "\n",
    "dx = dx.reset_index()\n",
    "dx = dx.rename_axis('E', axis=1)\n",
    "dx.columns = dx.columns.str.replace('index', 'Date')\n",
    "dx = dx.rename_axis(None, axis=1)\n",
    "\n",
    "dx['Date'] = pd.to_datetime(dx['Date'])  \n",
    "\n",
    "dayyy = datetime.strftime(datetime.now(), \"%Y/%m/%d\")\n",
    "t = pd.to_datetime(dayyy)\n",
    "t = pd.to_datetime(t)\n",
    "\n",
    "start_date = t  - timedelta(days = 5)\n",
    "end_date = t + timedelta(days = 120)\n",
    "\n",
    "mask = (dx['Date'] > start_date) & (dx['Date'] <= end_date)\n",
    "Spiral_hits = dx.loc[mask]\n",
    "Spiral_hits = Spiral_hits.sort_values(by=['Date'])\n",
    "\n",
    "Spiral_hits.head(15).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_Spi = Spiral_hits.head(30)\n",
    "dz_Spi.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','Spi.csv'), index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6bfc06",
   "metadata": {},
   "source": [
    "## 2. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ecf9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(Spiral_hits, x='Date', y='Hit')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaec21e",
   "metadata": {},
   "source": [
    "# **V. NatSq.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464831e3",
   "metadata": {},
   "source": [
    "## 1. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65927ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NatSq = NatSq.copy()\n",
    "NatSq = NatSq.drop(['Type'], axis=1)\n",
    "\n",
    "# Match every dates to cols\n",
    "\n",
    "for col in NatSq.columns[1:]:\n",
    "    NatSq[col] = ((pd.to_datetime(NatSq['Date']) + pd.to_timedelta(f'{col} days'))\n",
    "               .dt.strftime('%d/%m/%Y'))\n",
    "\n",
    "dx = NatSq[1:].unstack().value_counts(ascending=False)\n",
    "\n",
    "dx = pd.DataFrame(dx, columns=['Hit'])\n",
    "\n",
    "dx = dx.reset_index()\n",
    "dx = dx.rename_axis('E', axis=1)\n",
    "dx.columns = dx.columns.str.replace('index', 'Date')\n",
    "dx = dx.rename_axis(None, axis=1)\n",
    "\n",
    "dx['Date'] = pd.to_datetime(dx['Date'])\n",
    "\n",
    "start_date = t  - timedelta(days = 1)\n",
    "end_date = t + timedelta(days = 120)\n",
    "\n",
    "mask = (dx['Date'] > start_date) & (dx['Date'] <= end_date)\n",
    "NatSq_hits = dx.loc[mask]\n",
    "NatSq_hits = NatSq_hits.sort_values(by=['Date'])\n",
    "\n",
    "NatSq_hits.head(10).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2fddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_Nat = NatSq_hits.head(30)\n",
    "dz_Nat.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','NatSq.csv'), index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061f5a7",
   "metadata": {},
   "source": [
    "## 2. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd1b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(NatSq_hits, x='Date', y='Hit')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd052c5",
   "metadata": {},
   "source": [
    "# **VI. addPrice.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8421e",
   "metadata": {},
   "source": [
    "## 1. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "kek_p = helio.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610378a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hexxx = helio[helio.Date == \"31/10/2008\"]\n",
    "hexxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = priceadd.copy()\n",
    "pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9839319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outp = pd.DataFrame()\n",
    "\n",
    "for col in pa.columns:\n",
    "    outp[col] = pa[col]\n",
    "\n",
    "    if col not in (\"Date\", \"Price\"):\n",
    "        \n",
    "        for row, _ in helio.iterrows():\n",
    "            date = helio[\"Date\"][row]\n",
    "            dates_list = pa[\"Date\"].to_list()\n",
    "\n",
    "            if date in dates_list:\n",
    "                row_index = dates_list.index(date)\n",
    "                outp[col][row_index] = helio[col][row]\n",
    "\n",
    "output = outp.copy()                \n",
    "\n",
    "print(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b854d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA_1000\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "pa1k = output.copy()\n",
    "pa1k.Price = pa1k.Price / 1000 # <- change here\n",
    "\n",
    "# Add price to all planets\n",
    "\n",
    "for i in pa1k.columns[2:]:\n",
    "    pa1k[i] = pa1k[i] + pa1k.Price\n",
    "\n",
    "# if > 360 then -360 so it can stay within the circle \n",
    "\n",
    "for i in pa1k.columns[2:]:\n",
    "    for num, j in enumerate(pa1k[i]):\n",
    "        j = float(j)\n",
    "        if j > 360:\n",
    "            x = j - 360\n",
    "            pa1k[i].iloc[num] = x\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in pa1k.columns[2:]:\n",
    "    for num, i in enumerate(pa1k[planets]):\n",
    "        df_copy = helio.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            pa1k[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            pa1k[planets].iloc[num] = \" \"\n",
    "\n",
    "pa1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA_100\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "pa100 = output.copy()\n",
    "pa100.Price = pa100.Price / 100 # <- change here\n",
    "\n",
    "# Add price to all planets\n",
    "\n",
    "for i in pa100.columns[2:]:\n",
    "    pa100[i] = pa100[i] + pa100.Price\n",
    "\n",
    "# if > 360 then -360 so it can stay within the circle \n",
    "\n",
    "for i in pa100.columns[2:]:\n",
    "    for num, j in enumerate(pa100[i]):\n",
    "        j = float(j)\n",
    "        if j > 360:\n",
    "            x = j - 360\n",
    "            pa100[i].iloc[num] = x\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in pa100.columns[2:]:\n",
    "    for num, i in enumerate(pa100[planets]):\n",
    "        df_copy = helio.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            pa100[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            pa100[planets].iloc[num] = \" \"\n",
    "\n",
    "pa100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA_10\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "pa10 = output.copy()\n",
    "pa10.Price = pa10.Price / 10 # <- change here\n",
    "\n",
    "# Add price to all planets\n",
    "\n",
    "for i in pa10.columns[2:]:\n",
    "    pa10[i] = pa10[i] + pa10.Price\n",
    "\n",
    "# if > 360 then -360 so it can stay within the circle \n",
    "\n",
    "for i in pa10.columns[2:]:\n",
    "    for num, j in enumerate(pa10[i]):\n",
    "        j = float(j)\n",
    "        if j > 360:\n",
    "            x = j - 360\n",
    "            pa10[i].iloc[num] = x\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in pa10.columns[2:]:\n",
    "    for num, i in enumerate(pa10[planets]):\n",
    "        df_copy = helio.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            pa10[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            pa10[planets].iloc[num] = \" \"\n",
    "\n",
    "pa10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55fe0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA_1\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "pa1 = output.copy()\n",
    "pa1.Price = pa1.Price / 1 # <- change here\n",
    "\n",
    "# Add price to all planets\n",
    "\n",
    "for i in pa1.columns[2:]:\n",
    "    pa1[i] = pa1[i] + pa1.Price\n",
    "\n",
    "# if > 360 then -360 so it can stay within the circle \n",
    "\n",
    "for i in pa1.columns[2:]:\n",
    "    for num, j in enumerate(pa1[i]):\n",
    "        j = float(j)\n",
    "        if j > 360:\n",
    "            x = j - 360\n",
    "            pa1[i].iloc[num] = x\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in pa1.columns[2:]:\n",
    "    for num, i in enumerate(pa1[planets]):\n",
    "        df_copy = helio.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            pa1[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            pa1[planets].iloc[num] = \" \"\n",
    "\n",
    "pa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA_24:\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "pa24 = output.copy()\n",
    "pa24.Price = pa24.Price / 24 # <- change here\n",
    "\n",
    "# Add price to all planets\n",
    "\n",
    "for i in pa24.columns[2:]:\n",
    "    pa24[i] = pa24[i] + pa24.Price\n",
    "\n",
    "# if > 360 then -360 so it can stay within the circle \n",
    "\n",
    "for i in pa24.columns[2:]:\n",
    "    for num, j in enumerate(pa24[i]):\n",
    "        j = float(j)\n",
    "        if j > 360:\n",
    "            x = j - 360\n",
    "            pa24[i].iloc[num] = x\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in pa24.columns[2:]:\n",
    "    for num, i in enumerate(pa24[planets]):\n",
    "        df_copy = helio.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            pa24[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            pa24[planets].iloc[num] = \" \"\n",
    "\n",
    "pa24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9461624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA_263:\n",
    "\n",
    "# Copy price + Initialization of divisions\n",
    "# (1000,100,10,1,24,etc...)\n",
    "\n",
    "pa263 = output.copy()\n",
    "pa263.Price = pa263.Price / 263 # <- change here\n",
    "\n",
    "# Add price to all planets\n",
    "\n",
    "for i in pa263.columns[2:]:\n",
    "    pa263[i] = pa263[i] + pa263.Price\n",
    "\n",
    "# if > 360 then -360 so it can stay within the circle \n",
    "\n",
    "for i in pa263.columns[2:]:\n",
    "    for num, j in enumerate(pa263[i]):\n",
    "        j = float(j)\n",
    "        if j > 360:\n",
    "            x = j - 360\n",
    "            pa263[i].iloc[num] = x\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in pa263.columns[2:]:\n",
    "    for num, i in enumerate(pa263[planets]):\n",
    "        df_copy = helio.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            pa263[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            pa263[planets].iloc[num] = \" \"\n",
    "\n",
    "pa263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd37c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA_1440:\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "pa1440 = output.copy()\n",
    "pa1440.Price = pa1440.Price / 1440 # <- change here\n",
    "\n",
    "# Add price to all planets\n",
    "\n",
    "for i in pa1440.columns[2:]:\n",
    "    pa1440[i] = pa1440[i] + pa1440.Price\n",
    "\n",
    "# if > 360 then -360 so it can stay within the circle \n",
    "\n",
    "for i in pa1440.columns[2:]:\n",
    "    for num, j in enumerate(pa1440[i]):\n",
    "        j = float(j)\n",
    "        if j > 360:\n",
    "            x = j - 360\n",
    "            pa1440[i].iloc[num] = x\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in pa1440.columns[2:]:\n",
    "    for num, i in enumerate(pa1440[planets]):\n",
    "        df_copy = helio.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            pa1440[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            pa1440[planets].iloc[num] = \" \"\n",
    "\n",
    "pa1440"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb8994",
   "metadata": {},
   "source": [
    "#### **HIT addP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_p = pd.concat([pa1k, pa100, pa10, pa1, pa24, pa263, pa1440])\n",
    "\n",
    "adpod = total_p.copy()\n",
    "adpod = adpod.drop(['Price'], axis=1)\n",
    "\n",
    "good = adpod[1:].unstack().value_counts(ascending=True)\n",
    "\n",
    "good = pd.DataFrame(good, columns=['Hit'])\n",
    "\n",
    "good = good.reset_index()\n",
    "good = good.rename_axis('E', axis=1)\n",
    "good.columns = good.columns.str.replace('index', 'Date')\n",
    "good = good.rename_axis(None, axis=1)\n",
    "\n",
    "start_date = \"10/08/2022\"\n",
    "end_date = \"31/12/2025\"\n",
    "\n",
    "mask = (good['Date'] > start_date) & (good['Date'] <= end_date)\n",
    "good = good.loc[mask]\n",
    "\n",
    "# addp_hits.head(50)\n",
    "\n",
    "good = good.sort_values(by=['Date'], ascending=True)\n",
    "\n",
    "good['Date'] = good['Date'].apply(pd.to_datetime)\n",
    "\n",
    "start_date = \"10/08/2022\"\n",
    "end_date = \"31/12/2025\"\n",
    "\n",
    "mask = (good['Date'] > start_date) & (good['Date'] <= end_date)\n",
    "good = good.loc[mask]\n",
    "\n",
    "# addp_hits.head(50)\n",
    "\n",
    "good = good.sort_values(by=['Date'], ascending=True)\n",
    "good.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_ADDP = good.head(30)\n",
    "dz_ADDP.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','addPrice.csv'), index= False)\n",
    "dz_ADDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512f09b",
   "metadata": {},
   "source": [
    "## 2. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1460a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(good, x='Date', y='Hit')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab2e20",
   "metadata": {},
   "source": [
    "# **VII. TrNa.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00917db",
   "metadata": {},
   "source": [
    "## 1. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6220c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = points_na.copy()\n",
    "\n",
    "x.fillna(0, inplace=True)\n",
    "\n",
    "x_h = x[x[\"Type\"] == \"Helio\"]\n",
    "x_g = x[x[\"Type\"] == \"Geo\"]\n",
    "\n",
    "x_h = x_h.drop(['Type'], axis = 1)\n",
    "x_h = x_h.drop(['Angle'], axis = 1)\n",
    "x_h = x_h.drop(['Pair'], axis = 1)\n",
    "\n",
    "x_g = x_g.drop(['Type'], axis = 1)\n",
    "x_g = x_g.drop(['Angle'], axis = 1)\n",
    "x_g = x_g.drop(['Pair'], axis = 1)\n",
    "\n",
    "x_con = pd.concat([x_h, x_g])\n",
    "\n",
    "x_con['Date'] = pd.to_datetime(x_con['Date'])  \n",
    "start_date = t  - timedelta(days = 1)\n",
    "end_date = t + timedelta(days = 120)\n",
    "\n",
    "mask = (x_con['Date'] > start_date) & (x_con['Date'] <= end_date)\n",
    "\n",
    "x_hits = x_con.loc[mask]\n",
    "x_hits = x_hits.sort_values(by=['Date'], ascending = True)\n",
    "x_hi = x_con.loc[mask]\n",
    "x_hi = x_hi.sort_values(by=['Date'], ascending = True)\n",
    "\n",
    "x_hi.head(5).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_trna = x_hi.head(30)\n",
    "dz_trna.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','TrNa.csv'), index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5c9aaa",
   "metadata": {},
   "source": [
    "## 2. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(x_hi, x='Date', y='Points')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab2e20",
   "metadata": {},
   "source": [
    "# **VIII. TrTr.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657eb8e8",
   "metadata": {},
   "source": [
    "## 1. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6220c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = points_tr.copy()\n",
    "\n",
    "b.fillna(0, inplace=True)\n",
    "\n",
    "b_h = b[b[\"Type\"] == \"Helio\"]\n",
    "b_g = b[b[\"Type\"] == \"Geo\"]\n",
    "\n",
    "b_h = b_h.drop(['Type'], axis = 1)\n",
    "b_g = b_g.drop(['Type'], axis = 1)\n",
    "b_con = pd.concat([b_h, b_g])\n",
    "\n",
    "b_con['Date'] = pd.to_datetime(b_con['Date'])  \n",
    "\n",
    "start_date = t  - timedelta(days = 1)\n",
    "end_date = t + timedelta(days = 120)\n",
    "\n",
    "mask = (b_con['Date'] > start_date) & (b_con['Date'] <= end_date)\n",
    "b_hits = b_con.loc[mask]\n",
    "b_hits = b_hits.sort_values(by=['Date'], ascending = True)\n",
    "b_trtr = b_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943105f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_TRTR = b_trtr.head(30)\n",
    "dz_TRTR.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','TrTr.csv'), index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1299443",
   "metadata": {},
   "source": [
    "## 1. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf12a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(b_trtr, x='Date', y='Points')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b037607b",
   "metadata": {},
   "source": [
    "# **IX. MULT.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb14465a",
   "metadata": {},
   "source": [
    "## 1. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01698a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mult.copy()\n",
    "m.head(5)\n",
    "\n",
    "m['Date1'] = d1 = pd.to_datetime(m['Date1'])\n",
    "m['Date2'] = d2 = pd.to_datetime(m['Date2'])\n",
    "m['Date1'] = m['Date1'].dt.strftime('%Y/%m/%d')\n",
    "m['Date2'] = m['Date2'].dt.strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553af176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PANDA VERSION\n",
    "\n",
    "#from datetime import datetime \n",
    "\n",
    "#m618 = m.copy()\n",
    "\n",
    "#for i, col in enumerate(m618.columns[2:]):\n",
    "    #df1 = pd.to_datetime(m618['Date1'])\n",
    "    #df2 = pd.to_datetime(m618['Date2'])\n",
    "    #m618[col] =  df2 + ((df2 - df1) * (1.618 ** i))\n",
    "\n",
    "#m618['Date1'] = pd.to_datetime(m618['Date1'])\n",
    "#m618['Date2'] = pd.to_datetime(m618['Date2'])\n",
    "\n",
    "#m618['Date1'] = m618['Date1'].dt.strftime('%Y/%m/%d')\n",
    "#m618['Date2'] = m618['Date2'].dt.strftime('%Y/%m/%d')\n",
    "#m618['1'] = m618['1'].dt.strftime('%Y/%m/%d')\n",
    "#m618['2'] = m618['2'].dt.strftime('%Y/%m/%d')\n",
    "#m618['3'] = m618['3'].dt.strftime('%Y/%m/%d')\n",
    "#m618['4'] = m618['4'].dt.strftime('%Y/%m/%d')\n",
    "#m618['5'] = m618['5'].dt.strftime('%Y/%m/%d')\n",
    "#m618['6'] = m618['6'].dt.strftime('%Y/%m/%d')\n",
    "#m618['7'] = m618['7'].dt.strftime('%Y/%m/%d')\n",
    "#m618['8'] = m618['8'].dt.strftime('%Y/%m/%d')\n",
    "#m618['9'] = m618['9'].dt.strftime('%Y/%m/%d')\n",
    "#m618['10'] = m618['10'].dt.strftime('%Y/%m/%d')\n",
    "\n",
    "#m618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization Full 618\n",
    "\n",
    "op618 = (d2 - d1).dt.days.to_numpy().reshape(-1, 1) * (1.618 ** np.arange(1, 11)).reshape(1, -1)\n",
    "m618 = op618.astype('timedelta64[D]') + d2.to_numpy().reshape(-1, 1) \n",
    "\n",
    "m618 = pd.DataFrame(m618, columns=['1', '2', '3', '4', '5','6','7','8','9', '10'])\n",
    "\n",
    "m618['1'] = m618['1'].dt.strftime('%Y/%m/%d')\n",
    "m618['2'] = m618['2'].dt.strftime('%Y/%m/%d')\n",
    "m618['3'] = m618['3'].dt.strftime('%Y/%m/%d')\n",
    "m618['4'] = m618['4'].dt.strftime('%Y/%m/%d')\n",
    "m618['5'] = m618['5'].dt.strftime('%Y/%m/%d')\n",
    "m618['6'] = m618['6'].dt.strftime('%Y/%m/%d')\n",
    "m618['7'] = m618['7'].dt.strftime('%Y/%m/%d')\n",
    "m618['8'] = m618['8'].dt.strftime('%Y/%m/%d')\n",
    "m618['9'] = m618['9'].dt.strftime('%Y/%m/%d')\n",
    "m618['10'] = m618['10'].dt.strftime('%Y/%m/%d')\n",
    "\n",
    "m618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf18607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization Full 414\n",
    "\n",
    "op414 = (d2 - d1).dt.days.to_numpy().reshape(-1, 1) * (1.414 ** np.arange(1, 11)).reshape(1, -1)\n",
    "m414 = op414.astype('timedelta64[D]') + d2.to_numpy().reshape(-1, 1) \n",
    "\n",
    "m414 = pd.DataFrame(m414, columns=['1', '2', '3', '4', '5','6','7','8','9', '10'])\n",
    "\n",
    "m414['1'] = m414['1'].dt.strftime('%Y/%m/%d')\n",
    "m414['2'] = m414['2'].dt.strftime('%Y/%m/%d')\n",
    "m414['3'] = m414['3'].dt.strftime('%Y/%m/%d')\n",
    "m414['4'] = m414['4'].dt.strftime('%Y/%m/%d')\n",
    "m414['5'] = m414['5'].dt.strftime('%Y/%m/%d')\n",
    "m414['6'] = m414['6'].dt.strftime('%Y/%m/%d')\n",
    "m414['7'] = m414['7'].dt.strftime('%Y/%m/%d')\n",
    "m414['8'] = m414['8'].dt.strftime('%Y/%m/%d')\n",
    "m414['9'] = m414['9'].dt.strftime('%Y/%m/%d')\n",
    "m414['10'] = m414['10'].dt.strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization Full 732\n",
    "\n",
    "op732 = (d2 - d1).dt.days.to_numpy().reshape(-1, 1) * (1.732 ** np.arange(1, 11)).reshape(1, -1)\n",
    "m732 = op732.astype('timedelta64[D]') + d2.to_numpy().reshape(-1, 1) \n",
    "\n",
    "m732 = pd.DataFrame(m732, columns=['1', '2', '3', '4', '5','6','7','8','9', '10'])\n",
    "\n",
    "m732['1'] = m732['1'].dt.strftime('%Y/%m/%d')\n",
    "m732['2'] = m732['2'].dt.strftime('%Y/%m/%d')\n",
    "m732['3'] = m732['3'].dt.strftime('%Y/%m/%d')\n",
    "m732['4'] = m732['4'].dt.strftime('%Y/%m/%d')\n",
    "m732['5'] = m732['5'].dt.strftime('%Y/%m/%d')\n",
    "m732['6'] = m732['6'].dt.strftime('%Y/%m/%d')\n",
    "m732['7'] = m732['7'].dt.strftime('%Y/%m/%d')\n",
    "m732['8'] = m732['8'].dt.strftime('%Y/%m/%d')\n",
    "m732['9'] = m732['9'].dt.strftime('%Y/%m/%d')\n",
    "m732['10'] = m732['10'].dt.strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "multi = pd.concat([m618, m414, m732])\n",
    "\n",
    "tae = datetime.strftime(datetime.now(), \"%d/%m/%Y\")\n",
    "tx = pd.to_datetime(tae)\n",
    "tx = pd.to_datetime(tx)\n",
    "\n",
    "adpod = multi.copy()\n",
    "\n",
    "good = adpod[1:].unstack().value_counts(ascending=True)\n",
    "\n",
    "good = pd.DataFrame(good, columns=['Hit'])\n",
    "\n",
    "good = good.reset_index()\n",
    "good = good.rename_axis('E', axis=1)\n",
    "good.columns = good.columns.str.replace('index', 'Date')\n",
    "good = good.rename_axis(None, axis=1)\n",
    "\n",
    "start_date = tx  - timedelta(days = 1)\n",
    "end_date = tx + timedelta(days = 120)\n",
    "\n",
    "good['Date'] = pd.to_datetime(good['Date'])\n",
    "\n",
    "mask = (good['Date'] > start_date) & (good['Date'] <= end_date)\n",
    "good = good.loc[mask]\n",
    "\n",
    "# addp_hits.head(50)\n",
    "\n",
    "mult_hits = good.sort_values(by=['Date'], ascending=True)\n",
    "mult_hits.head(10).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f444b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_MULT = mult_hits.head(30)\n",
    "dz_MULT.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','Mult.csv'), index= False)\n",
    "dz_MULT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf1aa8",
   "metadata": {},
   "source": [
    "## 2. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016fdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(mult_hits, x='Date', y='Hit')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e1013e",
   "metadata": {},
   "source": [
    "# **X. FutureDates.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c8b61",
   "metadata": {},
   "source": [
    "## 1. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a499cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "futdat = FutureDate.copy()\n",
    "helio_cum = helio_cum.copy()\n",
    "\n",
    "fdd = pd.DataFrame()\n",
    "\n",
    "for col in futdat.columns:\n",
    "    fdd[col] = futdat[col]\n",
    "\n",
    "    if col not in (\"Date\", \"Price\"):\n",
    "        \n",
    "        for row, _ in helio_cum.iterrows():\n",
    "            date = helio_cum[\"Date\"][row]\n",
    "            dates_list = futdat[\"Date\"].to_list()\n",
    "\n",
    "            if date in dates_list:\n",
    "                row_index = dates_list.index(date)\n",
    "                fdd[col][row_index] = helio_cum[col][row]\n",
    "\n",
    "fdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD15\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 15\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd15 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd15.columns[1:]:\n",
    "    for num, i in enumerate(fd15[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd15[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd15[planets].iloc[num] = \" \"\n",
    "\n",
    "fd15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf23c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD30\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 30\n",
    "\n",
    "fd30 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd30.columns[1:]:\n",
    "    for num, i in enumerate(fd30[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd30[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd30[planets].iloc[num] = \" \"\n",
    "\n",
    "fd30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551767d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD45\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 45\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd45 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd45.columns[1:]:\n",
    "    for num, i in enumerate(fd45[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd45[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd45[planets].iloc[num] = \" \"\n",
    "\n",
    "fd45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42bf59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD60\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 60\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd60 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd60.columns[1:]:\n",
    "    for num, i in enumerate(fd60[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd60[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd60[planets].iloc[num] = \" \"\n",
    "\n",
    "fd60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa345689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD72\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 72\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd72 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd72.columns[1:]:\n",
    "    for num, i in enumerate(fd72[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd72[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd72[planets].iloc[num] = \" \"\n",
    "\n",
    "fd72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD90\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 90\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd90 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd90.columns[1:]:\n",
    "    for num, i in enumerate(fd90[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd90[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd90[planets].iloc[num] = \" \"\n",
    "\n",
    "fd90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD120\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 120\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd120 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd120.columns[1:]:\n",
    "    for num, i in enumerate(fd120[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd120[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd120[planets].iloc[num] = \" \"\n",
    "\n",
    "fd120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c30707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD144\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 144\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd144 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd144.columns[1:]:\n",
    "    for num, i in enumerate(fd144[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd144[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd144[planets].iloc[num] = \" \"\n",
    "\n",
    "fd144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ce79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD180\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 180\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd180 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd180.columns[1:]:\n",
    "    for num, i in enumerate(fd180[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd180[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd180[planets].iloc[num] = \" \"\n",
    "\n",
    "fd180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a605b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD360\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 360\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd360 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd360.columns[1:]:\n",
    "    for num, i in enumerate(fd360[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd360[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd360[planets].iloc[num] = \" \"\n",
    "\n",
    "fd360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4986f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD720\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 720\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd720 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd720.columns[1:]:\n",
    "    for num, i in enumerate(fd720[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd720[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd720[planets].iloc[num] = \" \"\n",
    "\n",
    "fd720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD1080\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 1080\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd1080 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd1080.columns[1:]:\n",
    "    for num, i in enumerate(fd1080[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd1080[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd1080[planets].iloc[num] = \" \"\n",
    "\n",
    "fd1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf9fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD1440\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 1440\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd1440 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd1440.columns[1:]:\n",
    "    for num, i in enumerate(fd1440[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd1440[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd1440[planets].iloc[num] = \" \"\n",
    "\n",
    "fd1440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a8ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FD1800\n",
    "\n",
    "output = pd.DataFrame()\n",
    "\n",
    "output[\"Date\"] = fdd[\"Date\"]\n",
    "\n",
    "for col in fdd.columns[1:]:\n",
    "    output[col] = fdd[col].astype(\"float64\") + 1800\n",
    "\n",
    "# Copy price + Initialization of divides (1000,100,10,1,24,etc...)\n",
    "\n",
    "fd1800 = output\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fd1800.columns[1:]:\n",
    "    for num, i in enumerate(fd1800[planets]):\n",
    "        df_copy = helio_cum.copy()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fd1800[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fd1800[planets].iloc[num] = \" \"\n",
    "\n",
    "fd1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d247d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_dates = pd.concat([fd15, fd30, fd45, fd60, fd72, fd90, fd120, fd144, fd180, fd360, fd720, fd1080, fd1440, fd1800])\n",
    "\n",
    "adpod = future_dates.copy()\n",
    "\n",
    "gfd = adpod[1:].unstack().value_counts(ascending=True)\n",
    "\n",
    "gfd = pd.DataFrame(gfd, columns=['Hit'])\n",
    "\n",
    "gfd = gfd.reset_index()\n",
    "gfd = gfd.rename_axis('E', axis=1)\n",
    "gfd.columns = gfd.columns.str.replace('index', 'Date')\n",
    "gfd = gfd.rename_axis(None, axis=1)\n",
    "\n",
    "gfd.drop(gfd.tail(1).index,inplace=True)\n",
    "\n",
    "\n",
    "gfd['Date'] = pd.to_datetime(gfd['Date'])\n",
    "\n",
    "start_date = t  - timedelta(days = 5)\n",
    "end_date = t + timedelta(days = 120)\n",
    "\n",
    "mask = (gfd['Date'] > start_date) & (gfd['Date'] <= end_date)\n",
    "gfd = gfd.loc[mask]\n",
    "\n",
    "gfd['Date'] = pd.to_datetime(gfd['Date'])\n",
    "\n",
    "# addp_hits.head(50)\n",
    "\n",
    "gfdE = gfd.sort_values(by=['Date'], ascending=True)\n",
    "gfdE.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f24ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lathit = lathit.copy()\n",
    "\n",
    "ex = pd.concat([gfdE, lathit])\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_FD = ex.head(30)\n",
    "dz_FD.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','FutureDate.csv'), index= False)\n",
    "dz_FD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f931e",
   "metadata": {},
   "source": [
    "## 2. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b964fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(ex, x='Date', y='Hit')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a435d2",
   "metadata": {},
   "source": [
    "# **XI. Fibs.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed3c57",
   "metadata": {},
   "source": [
    "## 1. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da366a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbb = pd.DataFrame()\n",
    "helio_cum = helio_cum.copy()\n",
    "fibs = fibs.copy()\n",
    "\n",
    "for col in fibs.columns:\n",
    "    fbb[col] = fibs[col]\n",
    "\n",
    "    if col not in (\"Date\"):\n",
    "        \n",
    "        for row, _ in helio_cum.iterrows():\n",
    "            date = helio_cum[\"Date\"][row]\n",
    "            dates_list = fibs[\"Date\"].to_list()\n",
    "\n",
    "            if date in dates_list:\n",
    "                row_index = dates_list.index(date)\n",
    "                fbb[col][row_index] = helio_cum[col][row]\n",
    "\n",
    "fbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for i in range(len(fbb[\"Date\"]) - 1):\n",
    "    new_df = fbb.copy()[i:]\n",
    "    for k in new_df:\n",
    "        if k == \"Date\":\n",
    "            continue\n",
    "        for j in range(i + 1, len(fbb[k])):\n",
    "            new_df[k][j] = (float(new_df[k][i]) + ((float(new_df[k][j]) - float(new_df[k][i])) * 1.618))\n",
    "        new_df[k][i] = 0\n",
    "    dfs.append(new_df)\n",
    "\n",
    "for df in dfs:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f27fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat(dfs)\n",
    "test = test.round()\n",
    "fbb1 = test.copy()\n",
    "\n",
    "# for loop to catch which degrees is situated at which date in the future/past\n",
    "\n",
    "for planets in fbb1.columns[1:]:\n",
    "    for num, i in enumerate(fbb1[planets]):\n",
    "        df_copy = helio_cum.round()\n",
    "        target = df_copy[df_copy[planets] == float(i)]\n",
    "        type(planets)\n",
    "        type(df_copy)\n",
    "\n",
    "        Date = []\n",
    "\n",
    "        for date in target['Date']:\n",
    "            Date.append(date)\n",
    "\n",
    "        if len(Date) > 0:\n",
    "            Date_ok = Date[-1]\n",
    "            fbb1[planets].iloc[num] = Date_ok\n",
    "        else:\n",
    "            fbb1[planets].iloc[num] = \" \"\n",
    "\n",
    "fbb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a379de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adpod = fbb1.copy()\n",
    "\n",
    "gdeg = adpod[1:].unstack().value_counts(ascending=True)\n",
    "\n",
    "gdeg = pd.DataFrame(gdeg, columns=['Hit'])\n",
    "\n",
    "gdeg = gdeg.reset_index()\n",
    "gdeg = gdeg.rename_axis('E', axis=1)\n",
    "gdeg.columns = gdeg.columns.str.replace('index', 'Date')\n",
    "gdeg = gdeg.rename_axis(None, axis=1)\n",
    "\n",
    "gdeg = gdeg.sort_values(by=['Date'], ascending=True)\n",
    "gdeg.drop(gdeg.head(1).index,inplace=True) # drop first n rows\n",
    "\n",
    "gdeg['Date'] = gdeg['Date'].apply(pd.to_datetime)\n",
    "\n",
    "start_date = t  - timedelta(days = 1)\n",
    "end_date = t + timedelta(days = 120)\n",
    "\n",
    "mask = (gdeg['Date'] > start_date) & (gdeg['Date'] <= end_date)\n",
    "gdeg = gdeg.loc[mask]\n",
    "\n",
    "fib_hits = gdeg.sort_values(by=['Date'], ascending=True)\n",
    "fib_hits.head(10).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_Fib = fib_hits.head(30)\n",
    "dz_Fib.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','Fib.csv'), index= False)\n",
    "dz_Fib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78f6048",
   "metadata": {},
   "source": [
    "## 2. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(fib_hits, x='Date', y='Hit')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e0828e",
   "metadata": {},
   "source": [
    "# **XII. Retro.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e7f125",
   "metadata": {},
   "source": [
    "## 1. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0addf9a",
   "metadata": {},
   "source": [
    "*0 = 0 || 1 = True || 2 = Return*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1306e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_h = retrohits.copy()\n",
    "r_h = r_h.fillna(0)\n",
    "\n",
    "r_h['Date'] = pd.to_datetime(r_h['Date'])\n",
    "r_h['Hit'] = r_h['Merc'] + r_h['Ven'] + r_h['Mar'] + r_h['Jup'] + r_h['Sat'] + r_h['Ura'] + r_h['Nep'] + r_h['Plu']\n",
    "r_h = r_h.drop(['Merc', 'Ven', 'Mar', 'Jup', 'Sat', 'Ura', 'Nep', 'Plu'], axis=1)\n",
    "\n",
    "r_h['Date'] = pd.to_datetime(r_h['Date'])  \n",
    "\n",
    "start_date = t  - timedelta(days = 1)\n",
    "end_date = t + timedelta(days = 120)\n",
    "\n",
    "mask = (r_h['Date'] > start_date) & (r_h['Date'] <= end_date)\n",
    "\n",
    "rh_hits = r_h.loc[mask]\n",
    "rh_hits = rh_hits.sort_values(by=['Date'], ascending = True)\n",
    "\n",
    "rh_hits.head(15).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6628ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_Retro = rh_hits.head(30)\n",
    "dz_Retro.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','Retro.csv'), index= False)\n",
    "dz_Retro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f55dd5",
   "metadata": {},
   "source": [
    "## 2. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcde5ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(rh_hits, x='Date', y='Hit')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c6d9f",
   "metadata": {},
   "source": [
    "# **XIII. PriceTime.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e60ebc",
   "metadata": {},
   "source": [
    "## 1. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3498f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "p_t = nega.copy()\n",
    "\n",
    "p_t['Date'] = d = pd.to_datetime(p_t['Date'])\n",
    "p_t['Date'] = p_t['Date'].dt.strftime('%Y/%m/%d')\n",
    "\n",
    "twoday = datetime.strftime(datetime.now(), \"%Y/%m/%d\")\n",
    "t = pd.to_datetime(twoday)\n",
    "\n",
    "p_t['Elapsed'] = t - d\n",
    "p_t['Elapsed'] = p_t['Elapsed'].dt.days.to_numpy()\n",
    "\n",
    "p_t['Sqrt'] = p_t['Elapsed'] ** (1/2)\n",
    "p_t['Sqrt'] = p_t['Sqrt'].round(2)\n",
    "sq = p_t['Sqrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad684c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "op13 = (((sq / 13).to_numpy().reshape(-1, 1) + (np.arange(1, 22)).reshape(1, -1)) ** 2)\n",
    "pt13 = op13.astype('timedelta64[D]') + d.to_numpy().reshape(-1, 1)\n",
    "\n",
    "pt13 = pd.DataFrame(pt13, columns=['1', '2', '3', '4', '5','6','7','8','9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21'])\n",
    "\n",
    "pt13['1'] = pt13['1'].dt.strftime('%Y/%m/%d')\n",
    "pt13['2'] = pt13['2'].dt.strftime('%Y/%m/%d')\n",
    "pt13['3'] = pt13['3'].dt.strftime('%Y/%m/%d')\n",
    "pt13['4'] = pt13['4'].dt.strftime('%Y/%m/%d')\n",
    "pt13['5'] = pt13['5'].dt.strftime('%Y/%m/%d')\n",
    "pt13['6'] = pt13['6'].dt.strftime('%Y/%m/%d')\n",
    "pt13['7'] = pt13['7'].dt.strftime('%Y/%m/%d')\n",
    "pt13['8'] = pt13['8'].dt.strftime('%Y/%m/%d')\n",
    "pt13['9'] = pt13['9'].dt.strftime('%Y/%m/%d')\n",
    "pt13['10'] = pt13['10'].dt.strftime('%Y/%m/%d')\n",
    "pt13['11'] = pt13['11'].dt.strftime('%Y/%m/%d')\n",
    "pt13['12'] = pt13['12'].dt.strftime('%Y/%m/%d')\n",
    "pt13['13'] = pt13['13'].dt.strftime('%Y/%m/%d')\n",
    "pt13['14'] = pt13['14'].dt.strftime('%Y/%m/%d')\n",
    "pt13['15'] = pt13['15'].dt.strftime('%Y/%m/%d')\n",
    "pt13['16'] = pt13['16'].dt.strftime('%Y/%m/%d')\n",
    "pt13['17'] = pt13['17'].dt.strftime('%Y/%m/%d')\n",
    "pt13['18'] = pt13['18'].dt.strftime('%Y/%m/%d')\n",
    "pt13['19'] = pt13['19'].dt.strftime('%Y/%m/%d')\n",
    "pt13['20'] = pt13['20'].dt.strftime('%Y/%m/%d')\n",
    "pt13['21'] = pt13['21'].dt.strftime('%Y/%m/%d')\n",
    "\n",
    "pt13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf72ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "op21 = (((sq / 21).to_numpy().reshape(-1, 1) + (np.arange(1, 22)).reshape(1, -1)) ** 2)\n",
    "pt21 = op21.astype('timedelta64[D]') + d.to_numpy().reshape(-1, 1)\n",
    "\n",
    "pt21 = pd.DataFrame(pt21, columns=['1', '2', '3', '4', '5','6','7','8','9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21'])\n",
    "pt21['1'] = pt21['1'].dt.strftime('%Y/%m/%d')\n",
    "pt21['2'] = pt21['2'].dt.strftime('%Y/%m/%d')\n",
    "pt21['3'] = pt21['3'].dt.strftime('%Y/%m/%d')\n",
    "pt21['4'] = pt21['4'].dt.strftime('%Y/%m/%d')\n",
    "pt21['5'] = pt21['5'].dt.strftime('%Y/%m/%d')\n",
    "pt21['6'] = pt21['6'].dt.strftime('%Y/%m/%d')\n",
    "pt21['7'] = pt21['7'].dt.strftime('%Y/%m/%d')\n",
    "pt21['8'] = pt21['8'].dt.strftime('%Y/%m/%d')\n",
    "pt21['9'] = pt21['9'].dt.strftime('%Y/%m/%d')\n",
    "pt21['10'] = pt21['10'].dt.strftime('%Y/%m/%d')\n",
    "pt21['11'] = pt21['11'].dt.strftime('%Y/%m/%d')\n",
    "pt21['12'] = pt21['12'].dt.strftime('%Y/%m/%d')\n",
    "pt21['13'] = pt21['13'].dt.strftime('%Y/%m/%d')\n",
    "pt21['14'] = pt21['14'].dt.strftime('%Y/%m/%d')\n",
    "pt21['15'] = pt21['15'].dt.strftime('%Y/%m/%d')\n",
    "pt21['16'] = pt21['16'].dt.strftime('%Y/%m/%d')\n",
    "pt21['17'] = pt21['17'].dt.strftime('%Y/%m/%d')\n",
    "pt21['18'] = pt21['18'].dt.strftime('%Y/%m/%d')\n",
    "pt21['19'] = pt21['19'].dt.strftime('%Y/%m/%d')\n",
    "pt21['20'] = pt21['20'].dt.strftime('%Y/%m/%d')\n",
    "pt21['21'] = pt21['21'].dt.strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2455cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "op34 = (((sq / 34).to_numpy().reshape(-1, 1) + (np.arange(1, 22)).reshape(1, -1)) ** 2)\n",
    "pt34 = op34.astype('timedelta64[D]') + d.to_numpy().reshape(-1, 1)\n",
    "\n",
    "pt34 = pd.DataFrame(pt34, columns=['1', '2', '3', '4', '5','6','7','8','9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21'])\n",
    "pt34['1'] = pt34['1'].dt.strftime('%Y/%m/%d')\n",
    "pt34['2'] = pt34['2'].dt.strftime('%Y/%m/%d')\n",
    "pt34['3'] = pt34['3'].dt.strftime('%Y/%m/%d')\n",
    "pt34['4'] = pt34['4'].dt.strftime('%Y/%m/%d')\n",
    "pt34['5'] = pt34['5'].dt.strftime('%Y/%m/%d')\n",
    "pt34['6'] = pt34['6'].dt.strftime('%Y/%m/%d')\n",
    "pt34['7'] = pt34['7'].dt.strftime('%Y/%m/%d')\n",
    "pt34['8'] = pt34['8'].dt.strftime('%Y/%m/%d')\n",
    "pt34['9'] = pt34['9'].dt.strftime('%Y/%m/%d')\n",
    "pt34['10'] = pt34['10'].dt.strftime('%Y/%m/%d')\n",
    "pt34['11'] = pt34['11'].dt.strftime('%Y/%m/%d')\n",
    "pt34['12'] = pt34['12'].dt.strftime('%Y/%m/%d')\n",
    "pt34['13'] = pt34['13'].dt.strftime('%Y/%m/%d')\n",
    "pt34['14'] = pt34['14'].dt.strftime('%Y/%m/%d')\n",
    "pt34['15'] = pt34['15'].dt.strftime('%Y/%m/%d')\n",
    "pt34['16'] = pt34['16'].dt.strftime('%Y/%m/%d')\n",
    "pt34['17'] = pt34['17'].dt.strftime('%Y/%m/%d')\n",
    "pt34['18'] = pt34['18'].dt.strftime('%Y/%m/%d')\n",
    "pt34['19'] = pt34['19'].dt.strftime('%Y/%m/%d')\n",
    "pt34['20'] = pt34['20'].dt.strftime('%Y/%m/%d')\n",
    "pt34['21'] = pt34['21'].dt.strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dafecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "op55 = (((sq / 55).to_numpy().reshape(-1, 1) + (np.arange(1, 22)).reshape(1, -1)) ** 2)\n",
    "pt55 = op55.astype('timedelta64[D]') + d.to_numpy().reshape(-1, 1)\n",
    "\n",
    "pt55 = pd.DataFrame(pt55, columns=['1', '2', '3', '4', '5','6','7','8','9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21'])\n",
    "pt55['1'] = pt55['1'].dt.strftime('%Y/%m/%d')\n",
    "pt55['2'] = pt55['2'].dt.strftime('%Y/%m/%d')\n",
    "pt55['3'] = pt55['3'].dt.strftime('%Y/%m/%d')\n",
    "pt55['4'] = pt55['4'].dt.strftime('%Y/%m/%d')\n",
    "pt55['5'] = pt55['5'].dt.strftime('%Y/%m/%d')\n",
    "pt55['6'] = pt55['6'].dt.strftime('%Y/%m/%d')\n",
    "pt55['7'] = pt55['7'].dt.strftime('%Y/%m/%d')\n",
    "pt55['8'] = pt55['8'].dt.strftime('%Y/%m/%d')\n",
    "pt55['9'] = pt55['9'].dt.strftime('%Y/%m/%d')\n",
    "pt55['10'] = pt55['10'].dt.strftime('%Y/%m/%d')\n",
    "pt55['11'] = pt55['11'].dt.strftime('%Y/%m/%d')\n",
    "pt55['12'] = pt55['12'].dt.strftime('%Y/%m/%d')\n",
    "pt55['13'] = pt55['13'].dt.strftime('%Y/%m/%d')\n",
    "pt55['14'] = pt55['14'].dt.strftime('%Y/%m/%d')\n",
    "pt55['15'] = pt55['15'].dt.strftime('%Y/%m/%d')\n",
    "pt55['16'] = pt55['16'].dt.strftime('%Y/%m/%d')\n",
    "pt55['17'] = pt55['17'].dt.strftime('%Y/%m/%d')\n",
    "pt55['18'] = pt55['18'].dt.strftime('%Y/%m/%d')\n",
    "pt55['19'] = pt55['19'].dt.strftime('%Y/%m/%d')\n",
    "pt55['20'] = pt55['20'].dt.strftime('%Y/%m/%d')\n",
    "pt55['21'] = pt55['21'].dt.strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f403d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "op89 = (((sq / 89).to_numpy().reshape(-1, 1) + (np.arange(1, 22)).reshape(1, -1)) ** 2)\n",
    "pt89 = op89.astype('timedelta64[D]') + d.to_numpy().reshape(-1, 1)\n",
    "\n",
    "pt89 = pd.DataFrame(pt89, columns=['1', '2', '3', '4', '5','6','7','8','9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21'])\n",
    "pt89['1'] = pt89['1'].dt.strftime('%Y/%m/%d')\n",
    "pt89['2'] = pt89['2'].dt.strftime('%Y/%m/%d')\n",
    "pt89['3'] = pt89['3'].dt.strftime('%Y/%m/%d')\n",
    "pt89['4'] = pt89['4'].dt.strftime('%Y/%m/%d')\n",
    "pt89['5'] = pt89['5'].dt.strftime('%Y/%m/%d')\n",
    "pt89['6'] = pt89['6'].dt.strftime('%Y/%m/%d')\n",
    "pt89['7'] = pt89['7'].dt.strftime('%Y/%m/%d')\n",
    "pt89['8'] = pt89['8'].dt.strftime('%Y/%m/%d')\n",
    "pt89['9'] = pt89['9'].dt.strftime('%Y/%m/%d')\n",
    "pt89['10'] = pt89['10'].dt.strftime('%Y/%m/%d')\n",
    "pt89['11'] = pt89['11'].dt.strftime('%Y/%m/%d')\n",
    "pt89['12'] = pt89['12'].dt.strftime('%Y/%m/%d')\n",
    "pt89['13'] = pt89['13'].dt.strftime('%Y/%m/%d')\n",
    "pt89['14'] = pt89['14'].dt.strftime('%Y/%m/%d')\n",
    "pt89['15'] = pt89['15'].dt.strftime('%Y/%m/%d')\n",
    "pt89['16'] = pt89['16'].dt.strftime('%Y/%m/%d')\n",
    "pt89['17'] = pt89['17'].dt.strftime('%Y/%m/%d')\n",
    "pt89['18'] = pt89['18'].dt.strftime('%Y/%m/%d')\n",
    "pt89['19'] = pt89['19'].dt.strftime('%Y/%m/%d')\n",
    "pt89['20'] = pt89['20'].dt.strftime('%Y/%m/%d')\n",
    "pt89['21'] = pt89['21'].dt.strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_hits = pd.concat([pt13, pt21, pt34, pt55, pt89])\n",
    "\n",
    "adpod = pt_hits.copy()\n",
    "\n",
    "dzea2 = adpod[1:].unstack().value_counts(ascending=True)\n",
    "\n",
    "dzea2 = pd.DataFrame(dzea2, columns=['Hit'])\n",
    "\n",
    "dzea2 = dzea2.reset_index()\n",
    "dzea2 = dzea2.rename_axis('E', axis=1)\n",
    "dzea2.columns = dzea2.columns.str.replace('index', 'Date')\n",
    "dzea2 = dzea2.rename_axis(None, axis=1)\n",
    "\n",
    "start_date = \"10/08/2022\"\n",
    "end_date = \"31/12/2022\"\n",
    "\n",
    "mask = (dzea2['Date'] > start_date) & (dzea2['Date'] <= end_date)\n",
    "dzea2 = dzea2.loc[mask]\n",
    "\n",
    "# addp_hits.head(50)\n",
    "\n",
    "dzea2 = dzea2.sort_values(by=['Date'], ascending=True)\n",
    "\n",
    "dzea2['Date'] = dzea2['Date'].apply(pd.to_datetime)\n",
    "\n",
    "start_date = t  - timedelta(days = 1)\n",
    "end_date = t + timedelta(days = 120)\n",
    "\n",
    "mask = (dzea2['Date'] > start_date) & (dzea2['Date'] <= end_date)\n",
    "dzea2 = dzea2.loc[mask]\n",
    "\n",
    "# addp_hits.head(50)\n",
    "\n",
    "pt_hit = dzea2.sort_values(by=['Date'], ascending=True)\n",
    "pt_hit.head(15).style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6635c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_Pt = pt_hit.head(30)\n",
    "dz_Pt.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','PriceTime.csv'), index= False)\n",
    "dz_Pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86fcbeb",
   "metadata": {},
   "source": [
    "## 2. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016fdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(pt_hit, x='Date', y='Hit')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee688d3",
   "metadata": {},
   "source": [
    "# **XIV. Sq9**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785013ef",
   "metadata": {},
   "source": [
    "## 1. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3156a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq9 = SQ9.copy()\n",
    "\n",
    "q = sq9['Sq9']\n",
    "sq9['0'] = d = pd.to_datetime(sq9['0'])\n",
    "op1 = ((q).to_numpy().reshape(-1, 1) * (np.arange(1, 8)).reshape(1, -1))\n",
    "sq9g = op1.astype('timedelta64[D]') + d.to_numpy().reshape(-1, 1)\n",
    "sq9g = pd.DataFrame(sq9g, columns=['45', '90', '135', '180', '225','270','315'])\n",
    "\n",
    "sq9g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a64b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "adpod = sq9g.copy()\n",
    "\n",
    "dzea2 = adpod[1:].unstack().value_counts(ascending=True)\n",
    "\n",
    "dzea2 = pd.DataFrame(dzea2, columns=['Hit'])\n",
    "\n",
    "dzea2 = dzea2.reset_index()\n",
    "dzea2 = dzea2.rename_axis('E', axis=1)\n",
    "dzea2.columns = dzea2.columns.str.replace('index', 'Date')\n",
    "dzea2 = dzea2.rename_axis(None, axis=1)\n",
    "\n",
    "dzea2 = dzea2.sort_values(by=['Date'], ascending=True)\n",
    "\n",
    "dzea2['Date'] = dzea2['Date'].apply(pd.to_datetime)\n",
    "\n",
    "start_date = t  - timedelta(days = 1)\n",
    "end_date = t + timedelta(days = 120)\n",
    "\n",
    "mask = (dzea2['Date'] > start_date) & (dzea2['Date'] <= end_date)\n",
    "dzea2 = dzea2.loc[mask]\n",
    "\n",
    "# addp_hits.head(50)\n",
    "\n",
    "ggggg = dzea2.sort_values(by=['Date'], ascending=True)\n",
    "ggggg.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc70b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_Sq9 = ggggg.head(30)\n",
    "dz_Sq9.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','Sq9.csv'), index= False)\n",
    "dz_Sq9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abaf764",
   "metadata": {},
   "source": [
    "## 2. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3392f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(ggggg, x='Date', y='Hit')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c866ca9d",
   "metadata": {},
   "source": [
    "# **XV. Natal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346dccd",
   "metadata": {},
   "source": [
    "## 1. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700669a0",
   "metadata": {},
   "source": [
    "### NATAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31/10/2008\n",
    "\n",
    "helcunn = helio_cum.copy() # DF WHERE I GET THE DATES (df_2)\n",
    "helcunn = helcunn.round()\n",
    "\n",
    "helcunn['Date'] = pd.to_datetime(helcunn['Date'])\n",
    "date_filter = \"2000/01/01\"\n",
    "date_filter = pd.to_datetime(date_filter)\n",
    "\n",
    "helcunn = helcunn[helcunn['Date'] > date_filter]\n",
    "\n",
    "s_d = \"31/10/2008\"\n",
    "nat = natal.copy()\n",
    "nat_h = nat.copy()\n",
    "\n",
    "nat_h.Degrees = nat_h.Planets.map(helio.set_index(\"Date\").loc[s_d])\n",
    "nat_h.Start_Date = nat_h.Planets.map(helio_cum.set_index(\"Date\").loc[s_d])\n",
    "nat_h.Now = nat_h.Planets.map(helio_cum.set_index(\"Date\").loc[today])\n",
    "nat_h.Cycles = (nat_h.Now - nat_h.Start_Date) / nat_h.Degrees\n",
    "\n",
    "nat_h['Cycles'] = nat_h['Cycles'].iloc[::].apply(np.floor)\n",
    "\n",
    "nat_h['0'] = (nat_h.Cycles * nat_h.Degrees) + nat_h.Start_Date\n",
    "nat_h['1'] = ((nat_h.Cycles + 1) * (nat_h.Degrees)) + nat_h.Start_Date\n",
    "nat_h['2'] = ((nat_h.Cycles + 2) * (nat_h.Degrees)) + nat_h.Start_Date\n",
    "nat_h['3'] = ((nat_h.Cycles + 3) * (nat_h.Degrees)) + nat_h.Start_Date\n",
    "nat_h['4'] = ((nat_h.Cycles + 4) * (nat_h.Degrees)) + nat_h.Start_Date\n",
    "nat_h['5'] = ((nat_h.Cycles + 5) * (nat_h.Degrees)) + nat_h.Start_Date\n",
    "nat_h['6'] = ((nat_h.Cycles + 6) * (nat_h.Degrees)) + nat_h.Start_Date\n",
    "nat_h['7'] = ((nat_h.Cycles + 7) * (nat_h.Degrees)) + nat_h.Start_Date\n",
    "nat_h['8'] = ((nat_h.Cycles + 8) * (nat_h.Degrees)) + nat_h.Start_Date\n",
    "nat_h['9'] = ((nat_h.Cycles + 9) * (nat_h.Degrees)) + nat_h.Start_Date\n",
    "\n",
    "nat_h['0'] = nat_h['0'].round()\n",
    "nat_h['1'] = nat_h['1'].round()\n",
    "nat_h['2'] = nat_h['2'].round()\n",
    "nat_h['3'] = nat_h['3'].round()\n",
    "nat_h['4'] = nat_h['4'].round()\n",
    "nat_h['5'] = nat_h['5'].round()\n",
    "nat_h['6'] = nat_h['6'].round()\n",
    "nat_h['7'] = nat_h['7'].round()\n",
    "nat_h['8'] = nat_h['8'].round()\n",
    "nat_h['9'] = nat_h['9'].round()\n",
    "\n",
    "nat_test = nat_h.copy() # DF WHERE I WANT TO REPLACE DEGREES VALUES BY THEIR CORRESPONDING DATES (df_1)\n",
    "\n",
    "dates              = helcunn.melt(id_vars=\"Date\", var_name=\"Planets\")\n",
    "numeric_cols       = nat_test.columns[nat_test.columns.str.fullmatch(\"\\d+\")]\n",
    "pairs              = nat_test.set_index(\"Planets\").filter(numeric_cols).stack().droplevel(-1).reset_index(name=\"value\")\n",
    "mapper             = pd.merge_asof(pairs.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   dates.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   on=\"value\",\n",
    "                                   direction=\"forward\").set_index(\"value\")[\"Date\"]\n",
    "\n",
    "nat_test[numeric_cols] = nat_test[numeric_cols].replace(mapper)\n",
    "\n",
    "nat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217cf9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03/01/2009\n",
    "\n",
    "helcunn = helio_cum.copy() # DF WHERE I GET THE DATES (df_2)\n",
    "helcunn = helcunn.round()\n",
    "\n",
    "helcunn['Date'] = pd.to_datetime(helcunn['Date'])\n",
    "date_filter = \"2000/01/01\"\n",
    "date_filter = pd.to_datetime(date_filter)\n",
    "\n",
    "helcunn = helcunn[helcunn['Date'] > date_filter]\n",
    "\n",
    "s_d1 = \"03/01/2009\"\n",
    "nat = natal.copy()\n",
    "nat_2 = nat.copy()\n",
    "\n",
    "nat_2.Degrees = nat_2.Planets.map(helio.set_index(\"Date\").loc[s_d1])\n",
    "nat_2.Start_Date = nat_2.Planets.map(helio_cum.set_index(\"Date\").loc[s_d1])\n",
    "nat_2.Now = nat_2.Planets.map(helio_cum.set_index(\"Date\").loc[today])\n",
    "nat_2.Cycles = (nat_2.Now - nat_2.Start_Date) / nat_2.Degrees\n",
    "\n",
    "nat_2['Cycles'] = nat_2['Cycles'].iloc[::].apply(np.floor)\n",
    "\n",
    "nat_2['0'] = (nat_2.Cycles * nat_2.Degrees) + nat_2.Start_Date\n",
    "nat_2['1'] = ((nat_2.Cycles + 1) * (nat_2.Degrees)) + nat_2.Start_Date\n",
    "nat_2['2'] = ((nat_2.Cycles + 2) * (nat_2.Degrees)) + nat_2.Start_Date\n",
    "nat_2['3'] = ((nat_2.Cycles + 3) * (nat_2.Degrees)) + nat_2.Start_Date\n",
    "nat_2['4'] = ((nat_2.Cycles + 4) * (nat_2.Degrees)) + nat_2.Start_Date\n",
    "nat_2['5'] = ((nat_2.Cycles + 5) * (nat_2.Degrees)) + nat_2.Start_Date\n",
    "nat_2['6'] = ((nat_2.Cycles + 6) * (nat_2.Degrees)) + nat_2.Start_Date\n",
    "nat_2['7'] = ((nat_2.Cycles + 7) * (nat_2.Degrees)) + nat_2.Start_Date\n",
    "nat_2['8'] = ((nat_2.Cycles + 8) * (nat_2.Degrees)) + nat_2.Start_Date\n",
    "nat_2['9'] = ((nat_2.Cycles + 9) * (nat_2.Degrees)) + nat_2.Start_Date\n",
    "\n",
    "nat_2['0'] = nat_2['0'].round()\n",
    "nat_2['1'] = nat_2['1'].round()\n",
    "nat_2['2'] = nat_2['2'].round()\n",
    "nat_2['3'] = nat_2['3'].round()\n",
    "nat_2['4'] = nat_2['4'].round()\n",
    "nat_2['5'] = nat_2['5'].round()\n",
    "nat_2['6'] = nat_2['6'].round()\n",
    "nat_2['7'] = nat_2['7'].round()\n",
    "nat_2['8'] = nat_2['8'].round()\n",
    "nat_2['9'] = nat_2['9'].round()\n",
    "\n",
    "nat_test2 = nat_2.copy() # DF WHERE I WANT TO REPLACE DEGREES VALUES BY THEIR CORRESPONDING DATES (df_1)\n",
    "\n",
    "dates              = helcunn.melt(id_vars=\"Date\", var_name=\"Planets\")\n",
    "numeric_cols       = nat_test2.columns[nat_test2.columns.str.fullmatch(\"\\d+\")]\n",
    "pairs              = nat_test2.set_index(\"Planets\").filter(numeric_cols).stack().droplevel(-1).reset_index(name=\"value\")\n",
    "mapper             = pd.merge_asof(pairs.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   dates.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   on=\"value\",\n",
    "                                   direction=\"forward\").set_index(\"value\")[\"Date\"]\n",
    "\n",
    "nat_test2[numeric_cols] = nat_test2[numeric_cols].replace(mapper)\n",
    "\n",
    "nat_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22/05/2010\n",
    "\n",
    "helcunn = helio_cum.copy() # DF WHERE I GET THE DATES (df_2)\n",
    "helcunn = helcunn.round()\n",
    "\n",
    "helcunn['Date'] = pd.to_datetime(helcunn['Date'])\n",
    "date_filter = \"2000/01/01\"\n",
    "date_filter = pd.to_datetime(date_filter)\n",
    "\n",
    "helcunn = helcunn[helcunn['Date'] > date_filter]\n",
    "\n",
    "s_d2 = \"22/05/2010\"\n",
    "nat = natal.copy()\n",
    "nat_3 = nat.copy()\n",
    "\n",
    "nat_3.Degrees = nat_3.Planets.map(helio.set_index(\"Date\").loc[s_d2])\n",
    "nat_3.Start_Date = nat_3.Planets.map(helio_cum.set_index(\"Date\").loc[s_d2])\n",
    "nat_3.Now = nat_3.Planets.map(helio_cum.set_index(\"Date\").loc[today])\n",
    "nat_3.Cycles = (nat_3.Now - nat_3.Start_Date) / nat_3.Degrees\n",
    "\n",
    "nat_3['Cycles'] = nat_3['Cycles'].iloc[::].apply(np.floor)\n",
    "\n",
    "nat_3['0'] = (nat_3.Cycles * nat_3.Degrees) + nat_3.Start_Date\n",
    "nat_3['1'] = ((nat_3.Cycles + 1) * (nat_3.Degrees)) + nat_3.Start_Date\n",
    "nat_3['2'] = ((nat_3.Cycles + 2) * (nat_3.Degrees)) + nat_3.Start_Date\n",
    "nat_3['3'] = ((nat_3.Cycles + 3) * (nat_3.Degrees)) + nat_3.Start_Date\n",
    "nat_3['4'] = ((nat_3.Cycles + 4) * (nat_3.Degrees)) + nat_3.Start_Date\n",
    "nat_3['5'] = ((nat_3.Cycles + 5) * (nat_3.Degrees)) + nat_3.Start_Date\n",
    "nat_3['6'] = ((nat_3.Cycles + 6) * (nat_3.Degrees)) + nat_3.Start_Date\n",
    "nat_3['7'] = ((nat_3.Cycles + 7) * (nat_3.Degrees)) + nat_3.Start_Date\n",
    "nat_3['8'] = ((nat_3.Cycles + 8) * (nat_3.Degrees)) + nat_3.Start_Date\n",
    "nat_3['9'] = ((nat_3.Cycles + 9) * (nat_3.Degrees)) + nat_3.Start_Date\n",
    "\n",
    "nat_3['0'] = nat_3['0'].round()\n",
    "nat_3['1'] = nat_3['1'].round()\n",
    "nat_3['2'] = nat_3['2'].round()\n",
    "nat_3['3'] = nat_3['3'].round()\n",
    "nat_3['4'] = nat_3['4'].round()\n",
    "nat_3['5'] = nat_3['5'].round()\n",
    "nat_3['6'] = nat_3['6'].round()\n",
    "nat_3['7'] = nat_3['7'].round()\n",
    "nat_3['8'] = nat_3['8'].round()\n",
    "nat_3['9'] = nat_3['9'].round()\n",
    "\n",
    "nat_test3 = nat_3.copy() # DF WHERE I WANT TO REPLACE DEGREES VALUES BY THEIR CORRESPONDING DATES (df_1)\n",
    "\n",
    "dates              = helcunn.melt(id_vars=\"Date\", var_name=\"Planets\")\n",
    "numeric_cols       = nat_test3.columns[nat_test3.columns.str.fullmatch(\"\\d+\")]\n",
    "pairs              = nat_test3.set_index(\"Planets\").filter(numeric_cols).stack().droplevel(-1).reset_index(name=\"value\")\n",
    "mapper             = pd.merge_asof(pairs.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   dates.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   on=\"value\",\n",
    "                                   direction=\"forward\").set_index(\"value\")[\"Date\"]\n",
    "\n",
    "nat_test3[numeric_cols] = nat_test3[numeric_cols].replace(mapper)\n",
    "\n",
    "nat_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea94d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17/12/2017\n",
    "\n",
    "helcunn = helio_cum.copy() # DF WHERE I GET THE DATES (df_2)\n",
    "helcunn = helcunn.round()\n",
    "\n",
    "helcunn['Date'] = pd.to_datetime(helcunn['Date'])\n",
    "date_filter = \"2000/01/01\"\n",
    "date_filter = pd.to_datetime(date_filter)\n",
    "\n",
    "helcunn = helcunn[helcunn['Date'] > date_filter]\n",
    "\n",
    "s_d3 = \"17/12/2017\"\n",
    "nat = natal.copy()\n",
    "nat_4 = nat.copy()\n",
    "\n",
    "nat_4.Degrees = nat_4.Planets.map(helio.set_index(\"Date\").loc[s_d3])\n",
    "nat_4.Start_Date = nat_4.Planets.map(helio_cum.set_index(\"Date\").loc[s_d3])\n",
    "nat_4.Now = nat_4.Planets.map(helio_cum.set_index(\"Date\").loc[today])\n",
    "nat_4.Cycles = (nat_4.Now - nat_4.Start_Date) / nat_4.Degrees\n",
    "\n",
    "nat_4['Cycles'] = nat_4['Cycles'].iloc[::].apply(np.floor)\n",
    "\n",
    "nat_4['0'] = (nat_4.Cycles * nat_4.Degrees) + nat_4.Start_Date\n",
    "nat_4['1'] = ((nat_4.Cycles + 1) * (nat_4.Degrees)) + nat_4.Start_Date\n",
    "nat_4['2'] = ((nat_4.Cycles + 2) * (nat_4.Degrees)) + nat_4.Start_Date\n",
    "nat_4['3'] = ((nat_4.Cycles + 3) * (nat_4.Degrees)) + nat_4.Start_Date\n",
    "nat_4['4'] = ((nat_4.Cycles + 4) * (nat_4.Degrees)) + nat_4.Start_Date\n",
    "nat_4['5'] = ((nat_4.Cycles + 5) * (nat_4.Degrees)) + nat_4.Start_Date\n",
    "nat_4['6'] = ((nat_4.Cycles + 6) * (nat_4.Degrees)) + nat_4.Start_Date\n",
    "nat_4['7'] = ((nat_4.Cycles + 7) * (nat_4.Degrees)) + nat_4.Start_Date\n",
    "nat_4['8'] = ((nat_4.Cycles + 8) * (nat_4.Degrees)) + nat_4.Start_Date\n",
    "nat_4['9'] = ((nat_4.Cycles + 9) * (nat_4.Degrees)) + nat_4.Start_Date\n",
    "\n",
    "nat_4['0'] = nat_4['0'].round()\n",
    "nat_4['1'] = nat_4['1'].round()\n",
    "nat_4['2'] = nat_4['2'].round()\n",
    "nat_4['3'] = nat_4['3'].round()\n",
    "nat_4['4'] = nat_4['4'].round()\n",
    "nat_4['5'] = nat_4['5'].round()\n",
    "nat_4['6'] = nat_4['6'].round()\n",
    "nat_4['7'] = nat_4['7'].round()\n",
    "nat_4['8'] = nat_4['8'].round()\n",
    "nat_4['9'] = nat_4['9'].round()\n",
    "\n",
    "nat_test4 = nat_4.copy() # DF WHERE I WANT TO REPLACE DEGREES VALUES BY THEIR CORRESPONDING DATES (df_1)\n",
    "\n",
    "dates              = helcunn.melt(id_vars=\"Date\", var_name=\"Planets\")\n",
    "numeric_cols       = nat_test4.columns[nat_test4.columns.str.fullmatch(\"\\d+\")]\n",
    "pairs              = nat_test4.set_index(\"Planets\").filter(numeric_cols).stack().droplevel(-1).reset_index(name=\"value\")\n",
    "mapper             = pd.merge_asof(pairs.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   dates.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   on=\"value\",\n",
    "                                   direction=\"forward\").set_index(\"value\")[\"Date\"]\n",
    "\n",
    "nat_test4[numeric_cols] = nat_test4[numeric_cols].replace(mapper)\n",
    "\n",
    "nat_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d989da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/03/2020\n",
    "\n",
    "helcunn = helio_cum.copy() # DF WHERE I GET THE DATES (df_2)\n",
    "helcunn = helcunn.round()\n",
    "\n",
    "helcunn['Date'] = pd.to_datetime(helcunn['Date'])\n",
    "date_filter = \"2000/01/01\"\n",
    "date_filter = pd.to_datetime(date_filter)\n",
    "\n",
    "helcunn = helcunn[helcunn['Date'] > date_filter]\n",
    "\n",
    "s_d4 = \"12/03/2020\"\n",
    "nat = natal.copy()\n",
    "nat_5 = nat.copy()\n",
    "\n",
    "nat_5.Degrees = nat_5.Planets.map(helio.set_index(\"Date\").loc[s_d4])\n",
    "nat_5.Start_Date = nat_5.Planets.map(helio_cum.set_index(\"Date\").loc[s_d4])\n",
    "nat_5.Now = nat_5.Planets.map(helio_cum.set_index(\"Date\").loc[today])\n",
    "nat_5.Cycles = (nat_5.Now - nat_5.Start_Date) / nat_5.Degrees\n",
    "\n",
    "nat_5['Cycles'] = nat_5['Cycles'].iloc[::].apply(np.floor)\n",
    "\n",
    "nat_5['0'] = (nat_5.Cycles * nat_5.Degrees) + nat_5.Start_Date\n",
    "nat_5['1'] = ((nat_5.Cycles + 1) * (nat_5.Degrees)) + nat_5.Start_Date\n",
    "nat_5['2'] = ((nat_5.Cycles + 2) * (nat_5.Degrees)) + nat_5.Start_Date\n",
    "nat_5['3'] = ((nat_5.Cycles + 3) * (nat_5.Degrees)) + nat_5.Start_Date\n",
    "nat_5['4'] = ((nat_5.Cycles + 4) * (nat_5.Degrees)) + nat_5.Start_Date\n",
    "nat_5['5'] = ((nat_5.Cycles + 5) * (nat_5.Degrees)) + nat_5.Start_Date\n",
    "nat_5['6'] = ((nat_5.Cycles + 6) * (nat_5.Degrees)) + nat_5.Start_Date\n",
    "nat_5['7'] = ((nat_5.Cycles + 7) * (nat_5.Degrees)) + nat_5.Start_Date\n",
    "nat_5['8'] = ((nat_5.Cycles + 8) * (nat_5.Degrees)) + nat_5.Start_Date\n",
    "nat_5['9'] = ((nat_5.Cycles + 9) * (nat_5.Degrees)) + nat_5.Start_Date\n",
    "\n",
    "nat_5['0'] = nat_5['0'].round()\n",
    "nat_5['1'] = nat_5['1'].round()\n",
    "nat_5['2'] = nat_5['2'].round()\n",
    "nat_5['3'] = nat_5['3'].round()\n",
    "nat_5['4'] = nat_5['4'].round()\n",
    "nat_5['5'] = nat_5['5'].round()\n",
    "nat_5['6'] = nat_5['6'].round()\n",
    "nat_5['7'] = nat_5['7'].round()\n",
    "nat_5['8'] = nat_5['8'].round()\n",
    "nat_5['9'] = nat_5['9'].round()\n",
    "\n",
    "nat_test5 = nat_5.copy() # DF WHERE I WANT TO REPLACE DEGREES VALUES BY THEIR CORRESPONDING DATES (df_1)\n",
    "\n",
    "dates              = helcunn.melt(id_vars=\"Date\", var_name=\"Planets\")\n",
    "numeric_cols       = nat_test5.columns[nat_test5.columns.str.fullmatch(\"\\d+\")]\n",
    "pairs              = nat_test5.set_index(\"Planets\").filter(numeric_cols).stack().droplevel(-1).reset_index(name=\"value\")\n",
    "mapper             = pd.merge_asof(pairs.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   dates.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   on=\"value\",\n",
    "                                   direction=\"forward\").set_index(\"value\")[\"Date\"]\n",
    "\n",
    "nat_test5[numeric_cols] = nat_test5[numeric_cols].replace(mapper)\n",
    "\n",
    "nat_test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb6b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25/04/2021\n",
    "\n",
    "helcunn = helio_cum.copy() # DF WHERE I GET THE DATES (df_2)\n",
    "helcunn = helcunn.round()\n",
    "\n",
    "helcunn['Date'] = pd.to_datetime(helcunn['Date'])\n",
    "date_filter = \"2000/01/01\"\n",
    "date_filter = pd.to_datetime(date_filter)\n",
    "\n",
    "helcunn = helcunn[helcunn['Date'] > date_filter]\n",
    "\n",
    "s_d5 = \"25/04/2021\"\n",
    "nat = natal.copy()\n",
    "nat_6 = nat.copy()\n",
    "\n",
    "nat_6.Degrees = nat_6.Planets.map(helio.set_index(\"Date\").loc[s_d5])\n",
    "nat_6.Start_Date = nat_6.Planets.map(helio_cum.set_index(\"Date\").loc[s_d5])\n",
    "nat_6.Now = nat_6.Planets.map(helio_cum.set_index(\"Date\").loc[today])\n",
    "nat_6.Cycles = (nat_6.Now - nat_6.Start_Date) / nat_6.Degrees\n",
    "\n",
    "nat_6['Cycles'] = nat_6['Cycles'].iloc[::].apply(np.floor)\n",
    "\n",
    "nat_6['0'] = (nat_6.Cycles * nat_6.Degrees) + nat_6.Start_Date\n",
    "nat_6['1'] = ((nat_6.Cycles + 1) * (nat_6.Degrees)) + nat_6.Start_Date\n",
    "nat_6['2'] = ((nat_6.Cycles + 2) * (nat_6.Degrees)) + nat_6.Start_Date\n",
    "nat_6['3'] = ((nat_6.Cycles + 3) * (nat_6.Degrees)) + nat_6.Start_Date\n",
    "nat_6['4'] = ((nat_6.Cycles + 4) * (nat_6.Degrees)) + nat_6.Start_Date\n",
    "nat_6['5'] = ((nat_6.Cycles + 5) * (nat_6.Degrees)) + nat_6.Start_Date\n",
    "nat_6['6'] = ((nat_6.Cycles + 6) * (nat_6.Degrees)) + nat_6.Start_Date\n",
    "nat_6['7'] = ((nat_6.Cycles + 7) * (nat_6.Degrees)) + nat_6.Start_Date\n",
    "nat_6['8'] = ((nat_6.Cycles + 8) * (nat_6.Degrees)) + nat_6.Start_Date\n",
    "nat_6['9'] = ((nat_6.Cycles + 9) * (nat_6.Degrees)) + nat_6.Start_Date\n",
    "\n",
    "nat_6['0'] = nat_6['0'].round()\n",
    "nat_6['1'] = nat_6['1'].round()\n",
    "nat_6['2'] = nat_6['2'].round()\n",
    "nat_6['3'] = nat_6['3'].round()\n",
    "nat_6['4'] = nat_6['4'].round()\n",
    "nat_6['5'] = nat_6['5'].round()\n",
    "nat_6['6'] = nat_6['6'].round()\n",
    "nat_6['7'] = nat_6['7'].round()\n",
    "nat_6['8'] = nat_6['8'].round()\n",
    "nat_6['9'] = nat_6['9'].round()\n",
    "\n",
    "nat_test6 = nat_6.copy() # DF WHERE I WANT TO REPLACE DEGREES VALUES BY THEIR CORRESPONDING DATES (df_1)\n",
    "\n",
    "dates              = helcunn.melt(id_vars=\"Date\", var_name=\"Planets\")\n",
    "numeric_cols       = nat_test6.columns[nat_test6.columns.str.fullmatch(\"\\d+\")]\n",
    "pairs              = nat_test6.set_index(\"Planets\").filter(numeric_cols).stack().droplevel(-1).reset_index(name=\"value\")\n",
    "mapper             = pd.merge_asof(pairs.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   dates.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   on=\"value\",\n",
    "                                   direction=\"forward\").set_index(\"value\")[\"Date\"]\n",
    "\n",
    "nat_test6[numeric_cols] = nat_test6[numeric_cols].replace(mapper)\n",
    "\n",
    "nat_test6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10/11/2021\n",
    "\n",
    "helcunn = helio_cum.copy() # DF WHERE I GET THE DATES (df_2)\n",
    "helcunn = helcunn.round()\n",
    "\n",
    "helcunn['Date'] = pd.to_datetime(helcunn['Date'])\n",
    "date_filter = \"2000/01/01\"\n",
    "date_filter = pd.to_datetime(date_filter)\n",
    "\n",
    "helcunn = helcunn[helcunn['Date'] > date_filter]\n",
    "\n",
    "s_d6 = \"10/11/2021\"\n",
    "nat = natal.copy()\n",
    "nat_7 = nat.copy()\n",
    "\n",
    "nat_7.Degrees = nat_7.Planets.map(helio.set_index(\"Date\").loc[s_d6])\n",
    "nat_7.Start_Date = nat_7.Planets.map(helio_cum.set_index(\"Date\").loc[s_d6])\n",
    "nat_7.Now = nat_7.Planets.map(helio_cum.set_index(\"Date\").loc[today])\n",
    "nat_7.Cycles = (nat_7.Now - nat_7.Start_Date) / nat_7.Degrees\n",
    "\n",
    "nat_7['Cycles'] = nat_7['Cycles'].iloc[::].apply(np.floor)\n",
    "\n",
    "nat_7['0'] = (nat_7.Cycles * nat_7.Degrees) + nat_7.Start_Date\n",
    "nat_7['1'] = ((nat_7.Cycles + 1) * (nat_7.Degrees)) + nat_7.Start_Date\n",
    "nat_7['2'] = ((nat_7.Cycles + 2) * (nat_7.Degrees)) + nat_7.Start_Date\n",
    "nat_7['3'] = ((nat_7.Cycles + 3) * (nat_7.Degrees)) + nat_7.Start_Date\n",
    "nat_7['4'] = ((nat_7.Cycles + 4) * (nat_7.Degrees)) + nat_7.Start_Date\n",
    "nat_7['5'] = ((nat_7.Cycles + 5) * (nat_7.Degrees)) + nat_7.Start_Date\n",
    "nat_7['6'] = ((nat_7.Cycles + 6) * (nat_7.Degrees)) + nat_7.Start_Date\n",
    "nat_7['7'] = ((nat_7.Cycles + 7) * (nat_7.Degrees)) + nat_7.Start_Date\n",
    "nat_7['8'] = ((nat_7.Cycles + 8) * (nat_7.Degrees)) + nat_7.Start_Date\n",
    "nat_7['9'] = ((nat_7.Cycles + 9) * (nat_7.Degrees)) + nat_7.Start_Date\n",
    "\n",
    "nat_7['0'] = nat_7['0'].round()\n",
    "nat_7['1'] = nat_7['1'].round()\n",
    "nat_7['2'] = nat_7['2'].round()\n",
    "nat_7['3'] = nat_7['3'].round()\n",
    "nat_7['4'] = nat_7['4'].round()\n",
    "nat_7['5'] = nat_7['5'].round()\n",
    "nat_7['6'] = nat_7['6'].round()\n",
    "nat_7['7'] = nat_7['7'].round()\n",
    "nat_7['8'] = nat_7['8'].round()\n",
    "nat_7['9'] = nat_7['9'].round()\n",
    "\n",
    "nat_test7 = nat_7.copy() # DF WHERE I WANT TO REPLACE DEGREES VALUES BY THEIR CORRESPONDING DATES (df_1)\n",
    "\n",
    "dates              = helcunn.melt(id_vars=\"Date\", var_name=\"Planets\")\n",
    "numeric_cols       = nat_test7.columns[nat_test7.columns.str.fullmatch(\"\\d+\")]\n",
    "pairs              = nat_test7.set_index(\"Planets\").filter(numeric_cols).stack().droplevel(-1).reset_index(name=\"value\")\n",
    "mapper             = pd.merge_asof(pairs.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   dates.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   on=\"value\",\n",
    "                                   direction=\"forward\").set_index(\"value\")[\"Date\"]\n",
    "\n",
    "nat_test7[numeric_cols] = nat_test7[numeric_cols].replace(mapper)\n",
    "\n",
    "nat_test7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e82bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18/06/2022\n",
    "\n",
    "helcunn = helio_cum.copy() # DF WHERE I GET THE DATES (df_2)\n",
    "helcunn = helcunn.round()\n",
    "\n",
    "helcunn['Date'] = pd.to_datetime(helcunn['Date'])\n",
    "date_filter = \"2000/01/01\"\n",
    "date_filter = pd.to_datetime(date_filter)\n",
    "\n",
    "helcunn = helcunn[helcunn['Date'] > date_filter]\n",
    "\n",
    "s_d7 = \"18/06/2022\"\n",
    "nat = natal.copy()\n",
    "nat_8 = nat.copy()\n",
    "\n",
    "nat_8.Degrees = nat_8.Planets.map(helio.set_index(\"Date\").loc[s_d7])\n",
    "nat_8.Start_Date = nat_8.Planets.map(helio_cum.set_index(\"Date\").loc[s_d7])\n",
    "nat_8.Now = nat_8.Planets.map(helio_cum.set_index(\"Date\").loc[today])\n",
    "nat_8.Cycles = (nat_8.Now - nat_8.Start_Date) / nat_8.Degrees\n",
    "\n",
    "nat_8['Cycles'] = nat_8['Cycles'].iloc[::].apply(np.floor)\n",
    "\n",
    "nat_8['0'] = (nat_8.Cycles * nat_8.Degrees) + nat_8.Start_Date\n",
    "nat_8['1'] = ((nat_8.Cycles + 1) * (nat_8.Degrees)) + nat_8.Start_Date\n",
    "nat_8['2'] = ((nat_8.Cycles + 2) * (nat_8.Degrees)) + nat_8.Start_Date\n",
    "nat_8['3'] = ((nat_8.Cycles + 3) * (nat_8.Degrees)) + nat_8.Start_Date\n",
    "nat_8['4'] = ((nat_8.Cycles + 4) * (nat_8.Degrees)) + nat_8.Start_Date\n",
    "nat_8['5'] = ((nat_8.Cycles + 5) * (nat_8.Degrees)) + nat_8.Start_Date\n",
    "nat_8['6'] = ((nat_8.Cycles + 6) * (nat_8.Degrees)) + nat_8.Start_Date\n",
    "nat_8['7'] = ((nat_8.Cycles + 7) * (nat_8.Degrees)) + nat_8.Start_Date\n",
    "nat_8['8'] = ((nat_8.Cycles + 8) * (nat_8.Degrees)) + nat_8.Start_Date\n",
    "nat_8['9'] = ((nat_8.Cycles + 9) * (nat_8.Degrees)) + nat_8.Start_Date\n",
    "\n",
    "nat_8['0'] = nat_8['0'].round()\n",
    "nat_8['1'] = nat_8['1'].round()\n",
    "nat_8['2'] = nat_8['2'].round()\n",
    "nat_8['3'] = nat_8['3'].round()\n",
    "nat_8['4'] = nat_8['4'].round()\n",
    "nat_8['5'] = nat_8['5'].round()\n",
    "nat_8['6'] = nat_8['6'].round()\n",
    "nat_8['7'] = nat_8['7'].round()\n",
    "nat_8['8'] = nat_8['8'].round()\n",
    "nat_8['9'] = nat_8['9'].round()\n",
    "\n",
    "nat_test8 = nat_8.copy() # DF WHERE I WANT TO REPLACE DEGREES VALUES BY THEIR CORRESPONDING DATES (df_1)\n",
    "\n",
    "dates              = helcunn.melt(id_vars=\"Date\", var_name=\"Planets\")\n",
    "numeric_cols       = nat_test8.columns[nat_test8.columns.str.fullmatch(\"\\d+\")]\n",
    "pairs              = nat_test8.set_index(\"Planets\").filter(numeric_cols).stack().droplevel(-1).reset_index(name=\"value\")\n",
    "mapper             = pd.merge_asof(pairs.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   dates.astype({\"value\": float}).sort_values(\"value\"),\n",
    "                                   on=\"value\",\n",
    "                                   direction=\"forward\").set_index(\"value\")[\"Date\"]\n",
    "\n",
    "nat_test8[numeric_cols] = nat_test8[numeric_cols].replace(mapper)\n",
    "\n",
    "nat_test8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50df6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "nat = pd.concat([nat_test, nat_test2, nat_test3, nat_test4, nat_test5, nat_test6, nat_test7, nat_test8])\n",
    "nat = nat.drop(columns=['Planets', 'Degrees', 'Start_Date', 'Now', 'Cycles'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a748d06a",
   "metadata": {},
   "source": [
    "### Revs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revgui = revgui.drop(columns=['Sat', 'Ura', 'Nep', 'Plu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "revgui = revgui.iloc[1: , :]\n",
    "revgui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699152f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31/10/2008\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"31/10/2008\", \"%d/%m/%Y\")\n",
    "\n",
    "input1 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [13, 57, 22, 7, 1],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output1 = pd.DataFrame()\n",
    "\n",
    "for col in input1.columns[0:3]:\n",
    "    output1[col] = input1[col]\n",
    "\n",
    "for col in input1.columns[3:]:\n",
    "    output1[col] = input1[col]\n",
    "    for row, _ in input1.iterrows():\n",
    "        delta = f'{int(input1[\"Days\"][row] * (input1[\"Rev\"][row] + int(col)))} days'\n",
    "        output1[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0919cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03/01/2009\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"03/01/2009\", \"%d/%m/%Y\")\n",
    "\n",
    "input2 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [13, 56, 22, 7, 1],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output2 = pd.DataFrame()\n",
    "\n",
    "for col in input2.columns[0:3]:\n",
    "    output2[col] = input2[col]\n",
    "\n",
    "for col in input2.columns[3:]:\n",
    "    output2[col] = input2[col]\n",
    "    for row, _ in input2.iterrows():\n",
    "        delta = f'{int(input2[\"Days\"][row] * (input2[\"Rev\"][row] + int(col)))} days'\n",
    "        output2[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22/05/2010\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"22/05/2010\", \"%d/%m/%Y\")\n",
    "\n",
    "input3 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [12, 51, 20, 6, 1],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output3 = pd.DataFrame()\n",
    "\n",
    "for col in input3.columns[0:3]:\n",
    "    output3[col] = input3[col]\n",
    "\n",
    "for col in input3.columns[3:]:\n",
    "    output3[col] = input3[col]\n",
    "    for row, _ in input3.iterrows():\n",
    "        delta = f'{int(input3[\"Days\"][row] * (input3[\"Rev\"][row] + int(col)))} days'\n",
    "        output3[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebda94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29/11/2013\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"29/11/2013\", \"%d/%m/%Y\")\n",
    "\n",
    "input4 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [8, 36, 14, 4, 0.72],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output4 = pd.DataFrame()\n",
    "\n",
    "for col in input4.columns[0:3]:\n",
    "    output4[col] = input4[col]\n",
    "\n",
    "for col in input4.columns[3:]:\n",
    "    output4[col] = input4[col]\n",
    "    for row, _ in input4.iterrows():\n",
    "        delta = f'{int(input4[\"Days\"][row] * (input4[\"Rev\"][row] + int(col)))} days'\n",
    "        output4[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b42cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29/11/2013\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"29/11/2013\", \"%d/%m/%Y\")\n",
    "\n",
    "input4 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [8, 36, 14, 4, 0.72],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output4 = pd.DataFrame()\n",
    "\n",
    "for col in input4.columns[0:3]:\n",
    "    output4[col] = input4[col]\n",
    "\n",
    "for col in input4.columns[3:]:\n",
    "    output4[col] = input4[col]\n",
    "    for row, _ in input4.iterrows():\n",
    "        delta = f'{int(input4[\"Days\"][row] * (input4[\"Rev\"][row] + int(col)))} days'\n",
    "        output4[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5eb6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17/12/2017\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"17/12/2017\", \"%d/%m/%Y\")\n",
    "\n",
    "input5 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [4, 19, 7, 2, 0.40],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output5 = pd.DataFrame()\n",
    "\n",
    "for col in input5.columns[0:3]:\n",
    "    output5[col] = input5[col]\n",
    "\n",
    "for col in input5.columns[3:]:\n",
    "    output5[col] = input5[col]\n",
    "    for row, _ in input5.iterrows():\n",
    "        delta = f'{int(input5[\"Days\"][row] * (input5[\"Rev\"][row] + int(col)))} days'\n",
    "        output5[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15/12/2018\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"15/12/2018\", \"%d/%m/%Y\")\n",
    "\n",
    "input6 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [3, 15, 6, 2, 0.32],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output6 = pd.DataFrame()\n",
    "\n",
    "for col in input6.columns[0:3]:\n",
    "    output6[col] = input6[col]\n",
    "\n",
    "for col in input6.columns[3:]:\n",
    "    output6[col] = input6[col]\n",
    "    for row, _ in input6.iterrows():\n",
    "        delta = f'{int(input6[\"Days\"][row] * (input6[\"Rev\"][row] + int(col)))} days'\n",
    "        output6[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e06416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26/06/2019\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"26/06/2019\", \"%d/%m/%Y\")\n",
    "\n",
    "input7 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [3, 13, 5, 1.71, 0.28],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output7 = pd.DataFrame()\n",
    "\n",
    "for col in input7.columns[0:3]:\n",
    "    output7[col] = input7[col]\n",
    "\n",
    "for col in input7.columns[3:]:\n",
    "    output7[col] = input7[col]\n",
    "    for row, _ in input7.iterrows():\n",
    "        delta = f'{int(input7[\"Days\"][row] * (input7[\"Rev\"][row] + int(col)))} days'\n",
    "        output7[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/03/2020\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"12/03/2020\", \"%d/%m/%Y\")\n",
    "\n",
    "input8 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [2, 10, 4, 1.38, 0.22],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output8 = pd.DataFrame()\n",
    "\n",
    "for col in input8.columns[0:3]:\n",
    "    output8[col] = input8[col]\n",
    "\n",
    "for col in input8.columns[3:]:\n",
    "    output8[col] = input8[col]\n",
    "    for row, _ in input8.iterrows():\n",
    "        delta = f'{int(input8[\"Days\"][row] * (input8[\"Rev\"][row] + int(col)))} days'\n",
    "        output8[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d454d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25/04/2021\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"25/04/2021\", \"%d/%m/%Y\")\n",
    "\n",
    "input9 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [1, 5, 2, 0.73, 0.12],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output9 = pd.DataFrame()\n",
    "\n",
    "for col in input9.columns[0:3]:\n",
    "    output9[col] = input9[col]\n",
    "\n",
    "for col in input9.columns[3:]:\n",
    "    output9[col] = input9[col]\n",
    "    for row, _ in input9.iterrows():\n",
    "        delta = f'{int(input9[\"Days\"][row] * (input9[\"Rev\"][row] + int(col)))} days'\n",
    "        output9[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ecbd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20/07/2021\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"20/07/2021\", \"%d/%m/%Y\")\n",
    "\n",
    "input10 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [1, 4, 1.85, 0.63, 0.10],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output10 = pd.DataFrame()\n",
    "\n",
    "for col in input10.columns[0:3]:\n",
    "    output10[col] = input10[col]\n",
    "\n",
    "for col in input10.columns[3:]:\n",
    "    output10[col] = input10[col]\n",
    "    for row, _ in input10.iterrows():\n",
    "        delta = f'{int(input10[\"Days\"][row] * (input10[\"Rev\"][row] + int(col)))} days'\n",
    "        output10[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6094e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20/10/2021\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"20/10/2021\", \"%d/%m/%Y\")\n",
    "\n",
    "input11 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [1, 3.64, 1.45, 0.52, 0.08],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output11 = pd.DataFrame()\n",
    "\n",
    "for col in input11.columns[0:3]:\n",
    "    output11[col] = input11[col]\n",
    "\n",
    "for col in input11.columns[3:]:\n",
    "    output11[col] = input11[col]\n",
    "    for row, _ in input11.iterrows():\n",
    "        delta = f'{int(input11[\"Days\"][row] * (input11[\"Rev\"][row] + int(col)))} days'\n",
    "        output11[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10/11/2021\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"10/11/2021\", \"%d/%m/%Y\")\n",
    "\n",
    "input12 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [1, 3.34, 1.35, 0.49, 0.07],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output12 = pd.DataFrame()\n",
    "\n",
    "for col in input12.columns[0:3]:\n",
    "    output12[col] = input12[col]\n",
    "\n",
    "for col in input12.columns[3:]:\n",
    "    output12[col] = input12[col]\n",
    "    for row, _ in input12.iterrows():\n",
    "        delta = f'{int(input12[\"Days\"][row] * (input12[\"Rev\"][row] + int(col)))} days'\n",
    "        output12[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f286bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18/06/2022\n",
    "\n",
    "import datetime\n",
    "\n",
    "starting_date = datetime.datetime.strptime(\"18/06/2022\", \"%d/%m/%Y\")\n",
    "\n",
    "input13 = pd.DataFrame({\"Planets\": [\"Earth\", \"Mer\", \"Ven\", \"Mar\", \"Jup\"],\n",
    "                       \"Days\": [365.2425, 88, 225, 687, 4330.6],\n",
    "                       \"Rev\": [1, 0.97, 0.38, 0.14, 0.02],\n",
    "                       \"0\": \"\",\n",
    "                       \"1\": \"\",\n",
    "                       \"2\": \"\",\n",
    "                       \"3\": \"\"\n",
    "                       })\n",
    "                       \n",
    "output13 = pd.DataFrame()\n",
    "\n",
    "for col in input13.columns[0:3]:\n",
    "    output13[col] = input13[col]\n",
    "\n",
    "for col in input13.columns[3:]:\n",
    "    output13[col] = input13[col]\n",
    "    for row, _ in input13.iterrows():\n",
    "        delta = f'{int(input13[\"Days\"][row] * (input13[\"Rev\"][row] + int(col)))} days'\n",
    "        output13[col][row] = (starting_date + pd.to_timedelta(delta)).strftime('%d/%m/%Y')\n",
    "\n",
    "output13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33da4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "revgood = pd.concat([output1, output2, output3, output4, output5, output6, output7, output8, output9, output10, output11, output12, output13])\n",
    "revgood = revgood.drop(columns=['Planets', 'Days', 'Rev'])\n",
    "naters = pd.concat([nat, revgood])\n",
    "\n",
    "flugg1 = naters.copy()\n",
    "\n",
    "gdeg2 = flugg1.unstack().value_counts(ascending=True)\n",
    "\n",
    "gdeg2 = pd.DataFrame(gdeg2, columns=['Hit'])\n",
    "\n",
    "gdeg2 = gdeg2.reset_index()\n",
    "gdeg2 = gdeg2.rename_axis('E', axis=1)\n",
    "gdeg2.columns = gdeg2.columns.str.replace('index', 'Date')\n",
    "gdeg2 = gdeg2.rename_axis(None, axis=1)\n",
    "\n",
    "#deg = gdeg2.sort_values(by=['Date'], ascending=True)\n",
    "gdeg2.drop(gdeg2.head(1).index,inplace=True) # drop first n rows\n",
    "\n",
    "gdeg2['Date'] = gdeg2['Date'].apply(pd.to_datetime, format = \"%d/%m/%Y\")\n",
    "\n",
    "start_date = t  - timedelta(days = 1)\n",
    "end_date = t + timedelta(days = 360)\n",
    "\n",
    "mask = (gdeg2['Date'] > start_date) & (gdeg2['Date'] <= end_date)\n",
    "gdeg2 = gdeg2.loc[mask]\n",
    "\n",
    "naters_hits = gdeg2.sort_values(by=['Date'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_Natal = naters_hits.head(30)\n",
    "dz_Natal.to_csv(os.path.join('STREAMLIT//streamlit//streamlit//data','Natal.csv'), index= False)\n",
    "dz_Natal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b8a05",
   "metadata": {},
   "source": [
    "## 2. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0bbd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(naters_hits, x='Date', y='Hit')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566da18f",
   "metadata": {},
   "source": [
    "# **FINAL CHART.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e23c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = fluchart.copy()\n",
    "\n",
    "fig = px.bar(c, x='Date', y='EP',\n",
    "             hover_data=['Date', 'EP'], color='EP', color_continuous_scale=px.colors.sequential.Cividis,\n",
    "             height=618)\n",
    "\n",
    "fig.update_traces(width=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3331c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_colorscales = px.colors.named_colorscales()\n",
    "  \n",
    "# printing color scales\n",
    "print(plotly_colorscales)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9e7e9156cfe6a39422315f0b6c888438b8276390da6e4dc465c601263f7841a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
